{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#documentacao-dos-projetos-de-machine-learning","title":"Documenta\u00e7\u00e3o dos Projetos de Machine Learning","text":""},{"location":"#autor","title":"Autor","text":"<p>Luiz Felipe Pimenta Berrettini</p> <p>Estudante do 4\u00b0 semestre de Ci\u00eancias de Dados e Neg\u00f3cios (CDN) na ESPM (Escola Superior de Propaganda e Marketing). </p> <p>Projetos de machine learning realizados em 2025.2, orientados e supervisionados pelo professor Humberto Sandmann.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Decision Tree - Data 29/08/2025</li> <li> KNN - Data 16/09/2025</li> <li> K-means e M\u00e9tricas de Avalia\u00e7\u00e3o - Data 19/09/2025</li> </ul>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"decision-tree/main/","title":"Projeto 1 - Decision Tree","text":""},{"location":"decision-tree/main/#modelo-de-machine-learning-arvore-de-decisoes","title":"Modelo de Machine Learning - \u00c1rvore de Decis\u00f5es","text":"<p>Para esse projeto, foi utilizado um dataset obtido no Kaggle. Os dados usados podem ser baixados aqui.</p>"},{"location":"decision-tree/main/#objetivo","title":"Objetivo","text":"<p>O dataset apresenta diversos dados relacionados \u00e0 cada um dos personagens da s\u00e9rie de livros A Song of Ice and Fire, escrita por George R. R. Martin, inspira\u00e7\u00e3o para a famosa s\u00e9rie Game of Thrones. O objetivo dessa an\u00e1lise \u00e9 o modelo fazer a predi\u00e7\u00e3o da import\u00e2ncia do personagem para a s\u00e9rie no sentido de trama. Uma vari\u00e1vel categ\u00f3rica ser\u00e1 criada a partir das vari\u00e1veis presentes no dataset, classificando a relev\u00e2ncia do personagem. Essa vari\u00e1vel ser\u00e1 avaliada pelo modelo de Machine Learning.</p>"},{"location":"decision-tree/main/#workflow","title":"Workflow","text":"<p>Os pontos \"etapas\" s\u00e3o o passo-a-passo da realiza\u00e7\u00e3o do projeto.</p>"},{"location":"decision-tree/main/#etapa-1-exploracao-de-dados","title":"Etapa 1 - Explora\u00e7\u00e3o de Dados","text":"<p>O dataset escolhido \u00e9 composto por 1946 linhas e 30 colunas, contendo um personagem distinto em cada linha e diversas informa\u00e7\u00f5es sobre cada um.</p>"},{"location":"decision-tree/main/#colunas-do-dataset","title":"Colunas do dataset","text":"Coluna Tipo Descri\u00e7\u00e3o <code>S.No</code> Inteiro Identificador \u00fanico do personagem <code>plod</code> Float Valor n\u00e3o especificado <code>name</code> String Nome do personagem <code>title</code> String Alcunha atribu\u00edda ao personagem dentro do mundo <code>gender</code> Bin\u00e1rio Sexo do personagem: 0 = feminino, 1 = masculino <code>culture</code> String Grupo social ao qual o personagem pertence <code>dateOfBirth</code> Inteiro Data de nascimento. Valores positivos = depois do ano 0, negativos = antes do ano 0 <code>DateoFdeath</code> Inteiro Data de morte. Valores positivos = depois do ano 0, negativos = antes do ano 0 <code>mother</code> String Nome da m\u00e3e do personagem <code>father</code> String Nome do pai do personagem <code>heir</code> String Nome do herdeiro do personagem <code>house</code> String Nome da casa \u00e0 qual o personagem pertence <code>spouse</code> String Nome do c\u00f4njuge do personagem <code>book1</code> Bin\u00e1rio Indica se o personagem apareceu no primeiro livro <code>book2</code> Bin\u00e1rio Indica se o personagem apareceu no segundo livro <code>book3</code> Bin\u00e1rio Indica se o personagem apareceu no terceiro livro <code>book4</code> Bin\u00e1rio Indica se o personagem apareceu no quarto livro <code>book5</code> Bin\u00e1rio Indica se o personagem apareceu no quinto livro <code>isAliveMother</code> Bin\u00e1rio Indica se a m\u00e3e do personagem est\u00e1 viva <code>isAliveFather</code> Bin\u00e1rio Indica se o pai do personagem est\u00e1 vivo <code>isAliveHeir</code> Bin\u00e1rio Indica se o herdeiro do personagem est\u00e1 vivo <code>isAliveSpouse</code> Bin\u00e1rio Indica se o c\u00f4njuge do personagem est\u00e1 vivo <code>isMarried</code> Bin\u00e1rio Indica se o personagem \u00e9 casado <code>isNoble</code> Bin\u00e1rio Indica se o personagem \u00e9 nobre <code>age</code> Inteiro Idade do personagem (refer\u00eancia: ano 305 D.C.) <code>numDeadRelations</code> Inteiro N\u00famero de personagens mortos com os quais o personagem se relaciona <code>boolDeadRelations</code> Bin\u00e1rio Indica se h\u00e1 personagens mortos relacionados ao personagem <code>isPopular</code> Bin\u00e1rio Indica se o personagem \u00e9 considerado popular <code>popularity</code> Float \u00cdndice entre 0 e 1 que indica o qu\u00e3o popular \u00e9 o personagem <code>isAlive</code> Bin\u00e1rio Indica se o personagem est\u00e1 vivo"},{"location":"decision-tree/main/#estudo-da-coluna-plod","title":"Estudo da coluna <code>plod</code>","text":"<p>No dataset, temos uma coluna que possui um \u00edndice que aponta algo n\u00e3o identificado: o plod. Para investigar seu significado, s\u00e3o necess\u00e1rias algumas an\u00e1lises:</p> <ul> <li>Inspe\u00e7\u00e3o dos valores: Primeiro, foram realizadas algumas linhas de c\u00f3digo para verificar os valores da coluna;</li> </ul> Sa\u00eddaC\u00f3digo <p>Tipo de dado: float64</p> <p>Valor m\u00ednimo: 0.0</p> <p>Valor m\u00e1ximo: 1.0</p> <p>Valor m\u00e9dio: 0.366</p> <p>Exemplo de valor: 0.946</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/decision-tree/dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\nprint(f\"Tipo de dado: {df[\"plod\"].dtype}\\n\")\nprint(f\"Valor m\u00ednimo: {df[\"plod\"].min()}\\n\")\nprint(f\"Valor m\u00e1ximo: {df[\"plod\"].max()}\\n\")\nprint(f\"Valor m\u00e9dio: {format(df[\"plod\"].mean(), \".3f\")}\\n\")\nprint(f\"Exemplo de valor: {df.loc[0, \"plod\"]}\")\n</code></pre> <p>A an\u00e1lise da sa\u00edda obtida nos permite observar que os valores est\u00e3o sempre no intervalo [0,1], sugerindo que representam uma probabilidade ou \u00edndice normalizado.</p> <ul> <li>Correla\u00e7\u00f5es entre <code>plod</code> e as outras colunas: Levando isso em considera\u00e7\u00e3o, \u00e9 necess\u00e1rio realizar um c\u00e1lculo de correla\u00e7\u00f5es para descobrir a principal vari\u00e1vel no c\u00e1lculo do plod:</li> </ul> Sa\u00eddaC\u00f3digo <p>popularity: 0.35458415491153905</p> <p>isAliveFather: -0.3525990385007833</p> <p>book4: -0.4041512952984149</p> <p>isAlive: -0.41731839569897605</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/decision-tree/dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\ndf_numerico = df.select_dtypes(include=[\"number\"])\n\ncorrel = df_numerico.corr()[\"plod\"].sort_values(ascending=False)\n\nfor col, corr in correl.items():\n    if (corr &gt; 0.3 or corr &lt; -0.3) and corr != 1:\n        print(f\"{col}: {corr}\\n\")\n</code></pre> <p>\u00c9 poss\u00edvel observar que a correla\u00e7\u00e3o mais forte entre plod e qualquer outra coluna no dataset \u00e9 com a coluna isAlive. Esse dado nos permite criar uma hip\u00f3tese de que plod \u00e9 a estimativa da probabilidade de morte do personagem.</p> <ul> <li>Compara\u00e7\u00e3o com a coluna <code>isAlive</code>: Em seguida, para verificar a hip\u00f3tese estabelecida, ser\u00e1 feito um gr\u00e1fico de boxplot para analisar a rela\u00e7\u00e3o de plod e isAlive;</li> </ul> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:29.504215 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/decision-tree/dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\nplod_alive = df[df[\"isAlive\"] == 1][\"plod\"]\nplod_dead = df[df[\"isAlive\"] == 0][\"plod\"]\n\nplt.rcParams[\"figure.figsize\"] = (10, 5)\nfig, ax = plt.subplots(facecolor=\"white\")\nax.set_facecolor(\"white\")\n\nax.boxplot([plod_alive, plod_dead], tick_labels=[\"Vivo\", \"Morto\"],\n           patch_artist=True,\n           boxprops=dict(facecolor=\"lightblue\", color=\"black\"),\n           medianprops=dict(color=\"red\"))\n\nax.set_title(\"Distribui\u00e7\u00e3o de plod por estado de vida\", color=\"black\")\nax.set_ylabel(\"plod (probabilidade de morte)\", color=\"black\")\nax.set_xlabel(\"Estado de vida (isAlive)\", color=\"black\")\nax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7, color=\"gray\")\n\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.spines[\"left\"].set_color(\"black\")\nax.spines[\"bottom\"].set_color(\"black\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> <p>No gr\u00e1fico, observa-se que personagens vivos (isAlive = 1) tendem a possuir baixos valores de plod, enquanto personagens mortos (isAlive = 0) geralmente t\u00eam valores altos. Al\u00e9m disso, \u00e9 poss\u00edvel observar diversos outliers dentre os personagens vivos, que s\u00e3o provavelmente personagens que aparecem pouco e/ou possuem informa\u00e7\u00f5es incompletas. Essa ideia \u00e9 fortalecida pelo fato de que a vari\u00e1vel popularity (popularidade) tamb\u00e9m possui correla\u00e7\u00e3o moderada com plod.</p> <p>Portanto, os padr\u00f5es do gr\u00e1fico indicam, novamente, que plod funciona como uma estimativa da probabilidade de morte do personagem, refor\u00e7ando a hip\u00f3tese inicial. Essa coluna provavelmente foi calculada com algum modelo preditivo anterior.</p> <p>\u00c9 necess\u00e1rio ressaltar que isso \u00e9 uma observa\u00e7\u00e3o explorat\u00f3ria, baseada nos dados dispon\u00edveis, e ser\u00e1 considerada no pr\u00e9-processamento e na escolha das features do modelo.</p>"},{"location":"decision-tree/main/#exploracao-aprofundada-da-coluna-popularity","title":"Explora\u00e7\u00e3o aprofundada da coluna <code>popularity</code>","text":"<ul> <li>Estat\u00edsticas descritivas: Primeiramente, vamos calcular alguns valores essenciais dessa coluna;</li> </ul> Sa\u00eddaC\u00f3digo popularity count 1946 mean 0.0895843 std 0.160568 min 0 25% 0.0133779 50% 0.0334448 75% 0.0869565 max 1 <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/decision-tree/dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\nprint(df[\"popularity\"].describe().to_markdown())\n</code></pre> <p>Na sa\u00edda, observa-se que popularity \u00e9 um \u00edndice que indica a popularidade do personagem, variando entre 0 e 1, com o valor 0 para irrelevante e 1 para popular.</p> <ul> <li>Gr\u00e1fico de dispers\u00e3o de <code>popularity</code>: O gr\u00e1fico relaciona o \u00edndice popularity com a soma das 5 vari\u00e1veis book, que indicam a presen\u00e7a de um personagem em cada livro em bin\u00e1rio. Os livros considerados nessas vari\u00e1veis s\u00e3o apenas a narrativa principal da hist\u00f3ria, sem spin-offs e personagens que s\u00e3o apenas citados e referenciados.</li> </ul> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:29.661698 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/decision-tree/dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\ndf[\"book_freq\"] = df[[\"book1\", \"book2\", \"book3\", \"book4\", \"book5\"]].sum(axis=1)\n\nplt.rcParams[\"figure.figsize\"] = (10, 5)\nfig, ax = plt.subplots(facecolor=\"white\")\nax.set_facecolor(\"white\")\n\nax.scatter(df[\"book_freq\"], df[\"popularity\"], alpha=0.7, color=\"red\", edgecolor=\"black\")\n\nax.set_title(\"Popularidade X Frequ\u00eancia nos livros\", color=\"black\")\nax.set_xlabel(\"Frequ\u00eancia em livros (soma)\", color=\"black\")\nax.set_ylabel(\"Popularidade\", color=\"black\")\nax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7, color=\"gray\")\n\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.spines[\"left\"].set_color(\"black\")\nax.spines[\"bottom\"].set_color(\"black\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> <p>A an\u00e1lise do gr\u00e1fico indica que, de 1 at\u00e9 5 apari\u00e7\u00f5es, o n\u00famero de personagens populares aumenta de forma diretamente proporcional, com alguns out-liers.</p> <p>Contudo, podemos observar que diversos personagens que n\u00e3o apareceram na s\u00e9rie principal de livros, possuindo soma de apari\u00e7\u00f5es igual a 0, s\u00e3o extremamente populares. Isso acontece pois h\u00e1 personagens de spin-offs muito amados pela comunidade, al\u00e9m de outros personagens que s\u00e3o apenas citados ao longo da hist\u00f3ria, sem aparecer diretamente, e tamb\u00e9m adquirem alta popularidade.</p>"},{"location":"decision-tree/main/#etapa-2-pre-processamento","title":"Etapa 2 - Pr\u00e9-processamento","text":"<p>O objetivo do projeto \u00e9 realizar uma predi\u00e7\u00e3o da relev\u00e2ncia dos personagens na trama principal, a vari\u00e1vel categ\u00f3rica relevance que possuir\u00e1 as seguintes categorias: Low, Medium, High e Very High. </p>"},{"location":"decision-tree/main/#1-passo-criacao-de-book_freq","title":"1\u00b0 Passo: Cria\u00e7\u00e3o de <code>book_freq</code>","text":"<p>Primeiramente, \u00e9 importante criar uma vari\u00e1vel representante para a frequ\u00eancia em livros para cada personagem. Ao inv\u00e9s de utilizar 5 vari\u00e1veis book diferentes, criaremos a vari\u00e1vel boof_freq. Para isso, ser\u00e1 feita a soma dos 5 valores das vari\u00e1veis book, o que resultar\u00e1 em um intervalo de [0,5]. Contudo, para que esse valores sejam normalizados, e possuam um n\u00famero entre 0 e 1, \u00e9 feita a divis\u00e3o desse resultado por 5.</p> <pre><code>df[\"book_freq\"] = df[[\"book1\", \"book2\", \"book3\", \"book4\",\"book5\"]].sum(axis=1) / 5\n</code></pre>"},{"location":"decision-tree/main/#2-passo-selecao-de-colunas","title":"2\u00b0 Passo: Sele\u00e7\u00e3o de colunas","text":"<p>Em seguida, \u00e9 necess\u00e1rio definir quais s\u00e3o as vari\u00e1veis ser\u00e3o utilizadas para prever a relev\u00e2ncia. Elas s\u00e3o as seguintes:</p> <ul> <li> <p>plod: Se esse valor for alto, h\u00e1 maior chance do personagem ser irrelevante </p> </li> <li> <p>title: Se o personagem tiver um t\u00edtulo, qualquer que seja, j\u00e1 possui alguma relev\u00e2ncia </p> </li> <li> <p>culture: Se o personagem tiver alguma cultura, qualquer que seja, j\u00e1 possui alguma relev\u00e2ncia </p> </li> <li> <p>mother: Se o personagem tiver paretentesco revelado, provavelmente tem alguma import\u00e2ncia </p> </li> <li> <p>father: Se o personagem tiver paretentesco revelado, provavelmente tem alguma import\u00e2ncia </p> </li> <li> <p>heir: Se o personagem tiver paretentesco revelado, provavelmente tem alguma import\u00e2ncia </p> </li> <li> <p>house: Se o personagem tiver uma casa, deve ser mais relevante </p> </li> <li> <p>book_freq: Se o personagem aparece frequentemente, deve ser relevante </p> </li> <li> <p>isNoble: Se o personagem for um nobre, tem mais chances de ser importante </p> </li> <li> <p>popularity: Se o personagem for popular, tamb\u00e9m aumenta sua chance de relev\u00e2ncia </p> </li> </ul> <p>A sele\u00e7\u00e3o das colunas foi feita, em c\u00f3digo, da seguinte forma: </p><pre><code>cols = [\"plod\", \"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\",\n\"book_freq\", \"isNoble\", \"popularity\"]\n\ndf = df[cols]\n</code></pre><p></p>"},{"location":"decision-tree/main/#3-passo-tratamento-de-valores-faltantes","title":"3\u00b0 Passo: Tratamento de valores faltantes","text":"<p>Precisamos garantir que n\u00e3o existam valores faltantes no dataframe. Por isso, ser\u00e1 feita uma altera\u00e7\u00e3o em todas as linhas restantes que possuem valor NA. Contudo, temos que tratar diferentemente cada tipo de vari\u00e1vel para o preenchimento dos vazios. As regras utilizadas ser\u00e3o as seguintes:</p> <ul> <li> <p>Faltantes n\u00famericos ser\u00e3o preenchidos com a mediana da coluna - plod, popularity</p> </li> <li> <p>Faltantes categ\u00f3ricos nominais ser\u00e3o preenchidos com \"Unknown\" (Desconhecido) - title, culture, mother, father, heir, house</p> </li> <li> <p>Faltantes bin\u00e1rios ser\u00e3o preenchidos com a moda da coluna (valor mais frequente) - isNoble</p> </li> </ul> <pre><code>cols = [\"plod\", \"popularity\"]\nfor col in cols:\n    df.fillna({col: df[col].median()}, inplace=True)\n\ncols = [\"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\"]\nfor col in cols:\n    df.fillna({col: \"Unknown\"}, inplace=True)\n\ndf.fillna({\"isNoble\": df[\"isNoble\"].mode()[0]}, inplace=True)\n</code></pre>"},{"location":"decision-tree/main/#4-passo-binarizacao-dos-categoricos-nominais","title":"4\u00b0 Passo: Binariza\u00e7\u00e3o dos categ\u00f3ricos nominais","text":"<p>As vari\u00e1veis categ\u00f3ricas no dataframe tem, simplesmente, muitas categorias para a realiza\u00e7\u00e3o de Label ou One-hot Encoding. Al\u00e9m disso, o \u00fanico dado importante provindo dessas no modelo sendo criado \u00e9 se existem ou n\u00e3o essas informa\u00e7\u00f5es sobre o personagem. Portanto, as colunas title, culture, mother, father, heir e house ser\u00e3o binarizadas. Ou seja, se possu\u00edrem um valor, assumir\u00e3o o valor 1. Caso contr\u00e1rio, 0. </p> <p>Al\u00e9m disso, os nomes das colunas ser\u00e3o alterados, adicionando um \"has_\" antes do nome original da vari\u00e1vel.</p> <pre><code>cols = [\"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\"]\n\nfor col in cols:\n    df[f\"has_{col}\"] = (df[col] != \"Unknown\").astype(int)\n    df.drop(columns=[col], inplace=True)\n</code></pre>"},{"location":"decision-tree/main/#5-passo-inversao-e-renomeacao-de-plod","title":"5\u00b0 Passo: Invers\u00e3o e renomea\u00e7\u00e3o de <code>plod</code>","text":"<p>A vari\u00e1vel plod, que indica a probabilidade de morte, possui uma rela\u00e7\u00e3o inversamente proporcional \u00e0 relev\u00e2ncia do personagem. Por isso, \u00e9 necess\u00e1ria a invers\u00e3o dessa vari\u00e1vel. Al\u00e9m disso, renomear a vari\u00e1vel para survival_prob deixar\u00e1 mais claro o seu prop\u00f3sito.</p> <pre><code>df[\"survival_prob\"] = 1 - df[\"plod\"]\ndf.drop(columns=\"plod\", inplace=True)\n</code></pre>"},{"location":"decision-tree/main/#6-passo-criacao-da-variavel-target-relevance_category-a-partir-do-score-relevance_score","title":"6\u00b0 Passo: Cria\u00e7\u00e3o da vari\u00e1vel target <code>relevance_category</code> a partir do score <code>relevance_score</code>","text":"<p>Agora, precisamos criar a vari\u00e1vel categ\u00f3rica que ser\u00e1 avaliada pelo modelo. Utilizaremos a seguinte distribui\u00e7\u00e3o de pesos:</p> <ul> <li> <p>popularity: Popularidade - 25%</p> </li> <li> <p>book_freq: Frequ\u00eancia de apari\u00e7\u00f5es - 25%</p> </li> <li> <p>survival_prob: Probabilidade de sobreviv\u00eancia - 15%</p> </li> <li> <p>isNoble: \u00c9 nobre - 10%</p> </li> <li> <p>has_title: Tem um t\u00edtulo - 10%</p> </li> <li> <p>has_house: Possui uma casa - 5%</p> </li> <li> <p>has_culture: Tem uma cultura - 5%</p> </li> <li> <p>has_mother + has_father + has_heir: Possui parentesco - 5%</p> </li> </ul> <p>Com o relevance_score definido, criaremos a nova coluna, relevance_category, a partir dos seguintes valores de score:</p> <ul> <li> <p>x &lt; 0.25: Low (Baixa relev\u00e2ncia)</p> </li> <li> <p>0.25 &lt;= x &lt; 0.5: Medium (Relev\u00e2ncia m\u00e9dia)</p> </li> <li> <p>0.5 &lt;= x &lt; 0.75: High (Alta relev\u00e2ncia)</p> </li> <li> <p>0.75 &lt;= x &lt;= 1: Very High (Relev\u00e2ncia muito alta)</p> </li> </ul>"},{"location":"decision-tree/main/#resultado-final-do-pre-processamento","title":"Resultado final do pr\u00e9-processamento","text":"Sa\u00eddaC\u00f3digo <p>Colunas ap\u00f3s tratamento: ['book_freq', 'isNoble', 'popularity', 'has_title', 'has_culture', 'has_mother', 'has_father', 'has_heir', 'has_house', 'survival_prob', 'relevance_score', 'relevance_category']</p> <p>Valores ausentes ap\u00f3s pr\u00e9-processamento: 0</p> <p>Formato do dataset final: (1946, 12)</p> <p>Features: 10</p> <p>Target: relevance_category</p> <p>Distribui\u00e7\u00e3o da vari\u00e1vel target:</p> relevance_category count Medium 1078 Low 458 High 379 Very High 31 <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/decision-tree/dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\n# 1\u00b0 Passo: Criando a coluna \"book_freq\", j\u00e1 normalizando-a\n\ndf[\"book_freq\"] = df[[\"book1\", \"book2\", \"book3\", \"book4\", \"book5\"]].sum(axis=1) / 5\n\n# 2\u00b0 Passo: Dropando colunas que n\u00e3o ser\u00e3o utilizadas\n\ncols = [\n    \"plod\", \"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\", \"book_freq\", \"isNoble\", \"popularity\"\n]\n\ndf = df[cols]\n\n# 3\u00b0 Passo: Tratamento de valores faltantes\n\ncols = [\"plod\", \"popularity\"]\nfor col in cols:\n    df.fillna({col: df[col].median()}, inplace=True)\n\ncols = [\"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\"]\nfor col in cols:\n    df.fillna({col: \"Unknown\"}, inplace=True)\n\ndf.fillna({\"isNoble\": df[\"isNoble\"].mode()[0]}, inplace=True)\n\n# 4\u00b0 Passo: Binariza\u00e7\u00e3o das vari\u00e1veis categ\u00f3ricas nominais\n\ncols = [\"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\"]\n\nfor col in cols:\n    df[f\"has_{col}\"] = (df[col] != \"Unknown\").astype(int)\n    df.drop(columns=[col], inplace=True)\n\n# 5\u00b0 Passo: Invers\u00e3o da vari\u00e1vel \"plod\" e renomea\u00e7\u00e3o para \"survival_prob\"\n\ndf[\"survival_prob\"] = 1 - df[\"plod\"]\ndf.drop(columns=\"plod\", inplace=True)\n\n# 6\u00b0 Passo: Criar vari\u00e1vel target \"relevance_category\" a partir do score \"relevance_score\"\n\ndef calculate_relevance_score(row):\n\n    score = (\n        row[\"popularity\"] * 0.25 +\n        row[\"book_freq\"] * 0.25 +\n        row[\"survival_prob\"] * 0.15 +\n        row[\"isNoble\"] * 0.10 +\n        row[\"has_title\"] * 0.10 +\n        row[\"has_house\"] * 0.05 +\n        row[\"has_culture\"] * 0.05 +\n        (row[\"has_mother\"] + row[\"has_father\"] + row[\"has_heir\"]) * 0.05 / 3\n    )\n\n    return min(max(score, 0), 1)\n\ndef categorize_relevance(score):\n    if score &lt; 0.25:\n        return \"Low\"\n    elif score &lt; 0.5:\n        return \"Medium\"\n    elif score &lt; 0.75:\n        return \"High\"\n    else:\n        return \"Very High\"\n\ndf[\"relevance_score\"] = df.apply(calculate_relevance_score, axis=1)\ndf[\"relevance_category\"] = df[\"relevance_score\"].apply(categorize_relevance)\n\nfeatures = [\n    \"book_freq\", \"popularity\", \"survival_prob\", \"isNoble\",    \n    \"has_title\", \"has_culture\", \"has_mother\", \"has_father\", \n    \"has_heir\", \"has_house\",\n]\n\ntarget = \"relevance_category\"\n\n# df.to_csv(\"dados_processado.csv\", index=False)\n\nprint(f\"Colunas ap\u00f3s tratamento: {df.columns.tolist()}\\n\")\nprint(f\"Valores ausentes ap\u00f3s pr\u00e9-processamento: {df.isnull().sum().sum()}\\n\") \nprint(f\"Formato do dataset final: {df.shape}\\n\")\nprint(f\"Features: {len(features)}\\n\")\nprint(f\"Target: {target}\\n\")\nprint(f\"Distribui\u00e7\u00e3o da vari\u00e1vel target:\\n\")\nprint(df[target].value_counts().to_markdown())\n</code></pre>"},{"location":"decision-tree/main/#etapa-3-divisao-de-dados","title":"Etapa 3 - Divis\u00e3o de dados","text":"<p>Na etapa de divis\u00e3o de dados, separaremos o conjunto de dados processado em dois grupos distintos:</p> <ul> <li> <p>Conjunto de Treino: \u00c9 utilizado para ensinar o modelo a reconhecer padr\u00f5es</p> </li> <li> <p>Conjunto de Teste: \u00c9 utilizado para avaliar o desempenho do modelo com dados ainda n\u00e3o vistos</p> </li> </ul> <p>Para realizar a divis\u00e3o, utilizaremos a fun\u00e7\u00e3o <code>train_test_split()</code> do <code>scikit-learn</code>. Os par\u00e2metros utilizados ser\u00e3o:</p> <ul> <li> <p>test_size=0.2: Define que 20% dos dados ser\u00e3o utilizados para teste, enquanto o restante ser\u00e1 usado para treino.</p> </li> <li> <p>random_state=42: Par\u00e2metro que controla o gerador de n\u00famero aleat\u00f3rios utilizado para sortear os dados antes de separ\u00e1-los. Garante reprodutibilidade.</p> </li> <li> <p>stratify=y: Esse atributo definido como y \u00e9 essencial devido \u00e0 natureza da coluna relevance_category. Com essa defini\u00e7\u00e3o, ser\u00e1 mantida a mesma propor\u00e7\u00e3o das categorias em ambos os conjuntos, reduzindo o vi\u00e9s.</p> </li> </ul> Sa\u00eddaC\u00f3digo <p>Treino: 1556 amostras</p> <p>Teste: 390 amostras</p> <p>Propor\u00e7\u00e3o: 80.0% treino, 20.0% teste</p> <p>Distribui\u00e7\u00e3o das classes - </p> <p>Treino:</p> relevance_category count Medium 862 Low 366 High 303 Very High 25 <p>Teste:</p> relevance_category count Medium 216 Low 92 High 76 Very High 6 <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"dados_processado.csv\")\n\nfeatures = [\n    \"book_freq\", \"popularity\", \"survival_prob\", \"isNoble\",\n    \"has_title\", \"has_culture\", \"has_mother\", \"has_father\", \n    \"has_heir\", \"has_house\"\n]\n\ntarget = \"relevance_category\"\n\nX = df[features]\ny = df[target]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nprint(f\"Treino: {X_train.shape[0]} amostras\\n\")\nprint(f\"Teste: {X_test.shape[0]} amostras\\n\")\nprint(f\"Propor\u00e7\u00e3o: {X_train.shape[0]/X.shape[0]*100:.1f}% treino, {X_test.shape[0]/X.shape[0]*100:.1f}% teste\\n\")\n\nprint(\"Distribui\u00e7\u00e3o das classes - \\n\")\nprint(\"Treino:\\n\")\nprint(y_train.value_counts().to_markdown(), \"\\n\")\nprint(\"Teste:\\n\")\nprint(y_test.value_counts().to_markdown(), \"\\n\")\n</code></pre> <p>Os dados, agora, est\u00e3o devidamente divididos. Esta divis\u00e3o adequada \u00e9 de extrema import\u00e2ncia, pois ajuda a evitar overfitting e garante que o modelo possa generalizar bem para novos personagens n\u00e3o vistos durante o treinamento.</p>"},{"location":"decision-tree/main/#etapa-4-treinamento-do-modelo","title":"Etapa 4 - Treinamento do Modelo","text":"<p>Agora, ser\u00e1 realizado o treinamento do modelo. O objetivo dessa etapa \u00e9 ensinar o algoritmo a reconhecer padr\u00f5es nos dados que s\u00e3o fornecidos, e determinar a import\u00e2ncia narrativa de cada personagem na s\u00e9rie principal de livros de A Song of Ice and Fire.</p> \u00c1rvoreC\u00f3digo <p>Precis\u00e3o do Modelo: 0.9513 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 book_freq 0.439754 2 survival_prob 0.200915 3 isNoble 0.146227 1 popularity 0.102306 5 has_culture 0.054061 9 has_house 0.034825 4 has_title 0.021911 6 has_mother 0.000000 7 has_father 0.000000 8 has_heir 0.000000 2025-09-28T18:11:31.035732 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom io import StringIO\n\ndf = pd.read_csv(\"dados_processado.csv\")\n\nfeatures = [\n    \"book_freq\", \"popularity\", \"survival_prob\", \"isNoble\",\n    \"has_title\", \"has_culture\", \"has_mother\", \"has_father\", \n    \"has_heir\", \"has_house\"\n]\n\ntarget = \"relevance_category\"\n\nX = df[features]\ny = df[target]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nclassifier = tree.DecisionTreeClassifier(random_state=42)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Precis\u00e3o do Modelo: {accuracy:.4f}\")\n\nfeature_importance = pd.DataFrame({\n    \"Feature\": classifier.feature_names_in_,\n    \"Import\u00e2ncia\": classifier.feature_importances_\n})\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.sort_values(by=\"Import\u00e2ncia\", ascending=False).to_html() + \"&lt;br&gt;\")\n\nplt.figure(figsize=(20, 10))\ntree.plot_tree(\n    classifier, \n    feature_names=features,\n    class_names=classifier.classes_,\n    filled=True,\n    rounded=True,\n    max_depth=3, \n    fontsize=10\n)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"decision-tree/main/#etapa-5-avaliacao-do-modelo","title":"Etapa 5 - Avalia\u00e7\u00e3o do modelo","text":""},{"location":"decision-tree/main/#acuracia-do-modelo","title":"Acur\u00e1cia do modelo","text":"<p>O modelo alcan\u00e7ou uma acur\u00e1cia impressionante de 95,13% no conjunto teste, demonstrando uma \u00f3tima capacidade de previs\u00e3o com personagens ainda n\u00e3o vistos com base nas features escolhidas.</p>"},{"location":"decision-tree/main/#importancia-das-features","title":"Import\u00e2ncia das features","text":"<p>A an\u00e1lise da import\u00e2ncia das features revela quais foram as vari\u00e1veis mais importantes para a previs\u00e3o e decis\u00f5es do modelo:</p> Feature Import\u00e2ncia Descri\u00e7\u00e3o <code>book_freq</code> 43,98% Frequ\u00eancia de apari\u00e7\u00e3o nos livros da s\u00e9rie principal <code>survival_prob</code> 20,09% Probabilidade de sobreviv\u00eancia <code>isNoble</code> 14,62% Status nobre <code>popularity</code> 10,23% \u00cdndice de popularidade <code>has_culture</code> 5,41% Possui cultura conhecida <code>has_house</code> 3,48% Pertence a uma casa <code>has_title</code> 2,19% Tem algum t\u00edtulo <code>has_mother</code> 0,00% H\u00e1 informa\u00e7\u00e3o sobre a m\u00e3e <code>has_father</code> 0,00% H\u00e1 informa\u00e7\u00e3o sobre o pai <code>has_heir</code> 0,00% Possui herdeiro"},{"location":"decision-tree/main/#insights-importantes-sobre-o-modelo","title":"Insights importantes sobre o modelo","text":"<ul> <li> <p>Frequ\u00eancia em livros \u00e9 determinante: A feature <code>book_freq</code> responde \u00e0 aproximadamente 44% da import\u00e2ncia, confirmando que personagens com mais apari\u00e7\u00f5es em diferentes livros da s\u00e9rie principal possuem maior import\u00e2ncia.</p> </li> <li> <p>Features desnecess\u00e1rias: O modelo tamb\u00e9m demonstrou que algumas features (has_mother, has_father, has_heir) n\u00e3o t\u00eam nenhuma import\u00e2ncia na predi\u00e7\u00e3o.</p> </li> </ul>"},{"location":"decision-tree/main/#etapa-6-relatorio-final","title":"Etapa 6 - Relat\u00f3rio Final","text":"<p>O projeto geral foi um sucesso, com a obten\u00e7\u00e3o de um modelo com uma acur\u00e1cia de 95,13%. O modelo, al\u00e9m de alta performance, possui features relevantes identificadas e bem estabelecidas: <code>book_freq</code>, <code>survival_prob</code> e <code>isNoble</code>.</p>"},{"location":"decision-tree/main/#limitacoes-do-modelo","title":"Limita\u00e7\u00f5es do modelo","text":"<p>Contudo, h\u00e1 limita\u00e7\u00f5es no modelo:</p> <ul> <li> <p>Features Redudantes: has_mother, has_father e has_heir possuem import\u00e2ncia nula para a predi\u00e7\u00e3o do sistema</p> </li> <li> <p>Poss\u00edvel vi\u00e9s: \u00c9 poss\u00edvel que, pela vari\u00e1vel relevance_score ter sido manualmente estabelecida, pode haver vi\u00e9s</p> </li> </ul>"},{"location":"decision-tree/main/#possiveis-melhorias","title":"Poss\u00edveis melhorias","text":"<ul> <li> <p>Valida\u00e7\u00e3o de <code>plod</code>: Durante a primeira etapa, na explora\u00e7\u00e3o da base de dados, poderia ter sido feita uma Regress\u00e3o Linear M\u00faltipla completa para validar completamente a hip\u00f3tese de que plod \u00e9 a probabilidade de morte do personagem.</p> </li> <li> <p>Remo\u00e7\u00e3o de features desnecess\u00e1rias: As features relacionadas \u00e0 parentesco podem ser removidas do modelo sem nenhum impacto na predi\u00e7\u00e3o.</p> </li> </ul>"},{"location":"decision-tree/main/#consideracoes-finais","title":"Considera\u00e7\u00f5es finais","text":"<p>A \u00e1rvore de decis\u00e3o se mostrou muito capaz de fazer a predi\u00e7\u00e3o de narrativas liter\u00e1rias complexas como A Song of Ice and Fire. Al\u00e9m do excelente resultado de acur\u00e1cia, foram providos insights importantes sobre a obra pelo modelo. </p> <p>Al\u00e9m disso, foi poss\u00edvel observar que tanto a Etapa 1 quanto a Etapa 2 foram muito mais longas do que as posteriores, demonstrando a import\u00e2ncia de entender e limpar o dataset antes do uso.</p>"},{"location":"k-means/main/","title":"Projeto 3 - K-Means","text":""},{"location":"k-means/main/#modelo-de-machine-learning-k-means","title":"Modelo de Machine Learning - K-Means","text":"<p>Para esse projeto, foi utilizado um dataset obtido no Kaggle. Os dados usados podem ser baixados aqui.</p> <p>A mesma base de dados utilizada para o projeto de KNN est\u00e1 sendo utilizada aqui. Contudo, esse projeto utilizar\u00e1 apenas a l\u00f3gica do Modelo 2 estudada no projeto anterior. Ou seja, evitaremos data leakage e ser\u00e1 aplicado o pr\u00e9-processamento apenas no conjunto de treino. Mais um ponto importante de esclarecer \u00e9 que, como a base de dados segue sendo a mesma, a explora\u00e7\u00e3o de dados, pr\u00e9-processamento e divis\u00e3o de dados ser\u00e3o basicamente a mesma coisa, mas agora, apenas com a l\u00f3gica do Modelo 2.</p>"},{"location":"k-means/main/#objetivo","title":"Objetivo","text":"<p>O dataset utilizado possui informa\u00e7\u00f5es sobre reservas em um hotel, e foi criado justamente para a cria\u00e7\u00e3o de modelos de machine learning com o objetivo de prever se um agendamento ser\u00e1, ou n\u00e3o, cancelado.</p> <p>Os dados originais para a cria\u00e7\u00e3o desse dataset foram obtidos em um artigo de dados, no site Science Direct. O artigo em quest\u00e3o foi escrito por Nuno Antonio, Ana de Almeida e Luis Nunes, e cont\u00e9m uma quantidade maior de dados do que a sua vers\u00e3o derivada do Kaggle, que estou utilizando para este projeto.</p>"},{"location":"k-means/main/#workflow","title":"Workflow","text":"<p>Os pontos \"etapas\" s\u00e3o o passo-a-passo da realiza\u00e7\u00e3o do projeto.</p>"},{"location":"k-means/main/#etapa-1-exploracao-de-dados","title":"Etapa 1 - Explora\u00e7\u00e3o de Dados","text":"<p>Primeiramente, deve ser feita a explora\u00e7\u00e3o dos dados da base, com o objetivo de compreender a forma como s\u00e3o estruturados os dados, sua natureza e poss\u00edvel signific\u00e2ncia para o modelo de predi\u00e7\u00e3o.</p> <p>O dataset \u00e9 composto por 36285 linhas e 17 colunas, com cada linha representando uma reserva distinta. Essa verifica\u00e7\u00e3o p\u00f4de ser feita com as linhas de c\u00f3digo abaixo;</p> Sa\u00eddaC\u00f3digo <p>(36285, 17)</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nprint(df.shape)\n</code></pre>"},{"location":"k-means/main/#colunas-do-dataset","title":"Colunas do dataset","text":"Coluna Tipo Descri\u00e7\u00e3o Booking_ID String Identificador \u00fanico da reserva number of adults Inteiro N\u00famero de adultos presentes na reserva number of children Inteiro N\u00famero de crian\u00e7as presentes na reserva number of weekend nights Inteiro Quantidade de noites em finais de semana reservadas number of week nights Inteiro Quantidade de noites em dias de semana reservadas type of meal String Plano de alimenta\u00e7\u00e3o escolhido pelo cliente car parking space Inteiro Vari\u00e1vel bin\u00e1ria que indica se um estacionamento de carro foi pedido ou incluso na reserva room type String Tipo de quarto reservado lead time Inteiro N\u00famero de dias entre a data da reserva e a data de chegada do cliente market segment type String Tipo de segmento do mercado associado \u00e0 reserva repeated Inteiro Vari\u00e1vel bin\u00e1ria que indica se a reserva \u00e9, ou n\u00e3o, repetida P-C Inteiro N\u00famero de reservas anteriores que foram canceladas pelo cliente antes do agendamento atual P-not-C Inteiro N\u00famero de reservas anteriores que n\u00e3o foram canceladas pelo cliente antes do agendamento atual average price Float Pre\u00e7o m\u00e9dio associado \u00e0 reserva special requests Inteiro N\u00famero de pedidos especiais feitos pelo convidado(a) date of reservation String Data da reserva booking status String Status da reserva (cancelada ou n\u00e3o cancelada)"},{"location":"k-means/main/#visualizacoes-das-variaveis","title":"Visualiza\u00e7\u00f5es das vari\u00e1veis","text":"<p>Em seguida, \u00e9 essencial realizar gr\u00e1ficos para visualizar como cada uma das vari\u00e1veis se comportam, com o objetivo de entender melhor a base da dados.</p> <p>Est\u00e1 se\u00e7\u00e3o ser\u00e1 divida para cada tipo de vari\u00e1vel, entre vari\u00e1veis quantitativas discretas, quantitativas cont\u00ednuas, qualitativas categ\u00f3ricas, bin\u00e1rias e, por fim, a vari\u00e1vel alvo.</p>"},{"location":"k-means/main/#variaveis-quantitativas-discretas","title":"Vari\u00e1veis Quantitativas Discretas","text":"number of adultsnumber of childrennumber of weekend nightsnumber of week nightslead timeP-CP-not-Cspecial requests Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:31.598332 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"number of adults\"].value_counts().sort_index().plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o do N\u00famero de Adultos por Reserva - Barras\")\nplt.xlabel(\"N\u00famero de Adultos\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:31.790390 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"number of children\"].value_counts().sort_index().plot(kind=\"bar\", color=\"lightcoral\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o do N\u00famero de Crian\u00e7as por Reserva - Barras\")\nplt.xlabel(\"N\u00famero de Crian\u00e7as\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:31.998701 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"number of weekend nights\"].value_counts().sort_index().plot(kind=\"bar\", color=\"lightgreen\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o de Noites de Fim de Semana por Reserva - Barras\")\nplt.xlabel(\"N\u00famero de Noites de Fim de Semana\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:32.229955 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"number of week nights\"].value_counts().sort_index().plot(kind=\"bar\", color=\"gold\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o de Noites de Dias de Semana por Reserva - Barras\")\nplt.xlabel(\"N\u00famero de Noites de Dias de Semana\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:32.532279 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\nlead_time_bins = pd.cut(df[\"lead time\"], bins=8)\nlead_time_bins.value_counts().sort_index().plot(kind=\"bar\", color=\"coral\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o do Lead Time (dias entre reserva e chegada) - Barras\")\nplt.xlabel(\"Intervalo de Dias\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=45)\nplt.grid(axis=\"y\", alpha=0.3)\nplt.tight_layout()\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:32.765244 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"P-C\"].value_counts().sort_index().plot(kind=\"bar\", color=\"orange\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o de Reservas Anteriormente Canceladas (P-C) - Barras\")\nplt.xlabel(\"N\u00famero de Reservas Anteriormente Canceladas\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:32.976179 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"P-not-C\"], bins=15, edgecolor=\"black\", alpha=0.7, color=\"blue\")\nplt.title(\"Distribui\u00e7\u00e3o de Reservas Anteriormente N\u00e3o Canceladas (P-not-C) - Histograma\")\nplt.xlabel(\"N\u00famero de Reservas Anteriormente N\u00e3o Canceladas\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:33.197491 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"special requests\"].value_counts().sort_index().plot(kind=\"bar\", color=\"purple\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o de Pedidos Especiais por Reserva - Barras\")\nplt.xlabel(\"N\u00famero de Pedidos Especiais\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"k-means/main/#variavel-quantitativa-continua-average-price","title":"Vari\u00e1vel Quantitativa Cont\u00ednua <code>average price</code>","text":"Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:33.405696 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"average price\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"red\")\nplt.title(\"Distribui\u00e7\u00e3o do Pre\u00e7o M\u00e9dio das Reservas - Histograma\")\nplt.xlabel(\"Pre\u00e7o M\u00e9dio\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"k-means/main/#variaveis-categoricas","title":"Vari\u00e1veis Categ\u00f3ricas","text":"type of mealroom typemarket segment type Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:33.618477 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 8))\ndf[\"type of meal\"].value_counts().plot(kind=\"bar\", color=\"lightseagreen\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o dos Tipos de Refei\u00e7\u00e3o - Barras\")\nplt.xlabel(\"Tipo de Refei\u00e7\u00e3o\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=45)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:33.821518 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 8))\ndf[\"room type\"].value_counts().plot(kind=\"bar\", color=\"mediumpurple\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o dos Tipos de Quarto - Barras\")\nplt.xlabel(\"Tipo de Quarto\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=45)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:34.054326 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 8))\ndf[\"market segment type\"].value_counts().plot(kind=\"bar\", color=\"salmon\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o dos Segmentos de Mercado - Barras\")\nplt.xlabel(\"Segmento de Mercado\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=45)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"k-means/main/#variaveis-binarias","title":"Vari\u00e1veis Bin\u00e1rias","text":"car parking spacerepeated Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:34.243372 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nlabels = [\"Sem estacionamento\", \"Com estacionamento\"]  \nvalues = df[\"car parking space\"].value_counts()\n\nplt.figure(figsize=(10, 8))\nplt.pie(values, labels=labels, autopct=lambda p: f\"{int(p * sum(values) / 100)}\", colors=[\"lightblue\", \"lightcoral\"])\nplt.title(\"Distribui\u00e7\u00e3o do Status das Reservas - Pizza\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:34.404900 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nlabels = [\"N\u00e3o Repetido\", \"Repetido\"]  \nvalues = df[\"repeated\"].value_counts()\n\nplt.figure(figsize=(10, 8))\nplt.pie(values, labels=labels, autopct=lambda p: f\"{int(p * sum(values) / 100)}\", colors=[\"lightgreen\", \"lightyellow\"])\nplt.title(\"Distribui\u00e7\u00e3o do Status das Reservas - Pizza\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"k-means/main/#variavel-alvo-booking-status","title":"Vari\u00e1vel Alvo <code>booking status</code>","text":"Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:34.566770 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nlabels = [\"Cancelado\", \"N\u00e3o Cancelado\"]  \nvalues = df[\"booking status\"].value_counts()\n\nplt.figure(figsize=(10, 8))\nplt.pie(values, labels=labels, autopct=lambda p: f\"{int(p * sum(values) / 100)}\", colors=[\"lightcoral\", \"lightgreen\"])\nplt.title(\"Distribui\u00e7\u00e3o do Status das Reservas - Pizza\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> <p>Atrav\u00e9s das an\u00e1lises, foi poss\u00edvel alcan\u00e7ar uma compreens\u00e3o mais aprofundada do funcionamento de cada uma das vari\u00e1veis no dataset, al\u00e9m de haver insights valiosos nesses gr\u00e1ficos. Esses dados ser\u00e3o essenciais para a escolha das vari\u00e1veis que ser\u00e3o utilizadas no modelo.</p>"},{"location":"k-means/main/#etapa-2-pre-processamento-e-divisao-de-dados","title":"Etapa 2 - Pr\u00e9-processamento e Divis\u00e3o de Dados","text":"<p>Nesta etapa, vamos fazer a divis\u00e3o e pr\u00e9-processamento dos dados. Como citado na introdu\u00e7\u00e3o, estaremos aplicando apenas o modelo em que o pr\u00e9-processamento \u00e9 realizado a partir do conjunto de treino e depois aplicado no conjunto de teste. Com isso, estamos evitando data leakage.</p>"},{"location":"k-means/main/#1-passo-identificacao-e-tratamento-de-valores-nulos","title":"1\u00b0 Passo: Identifica\u00e7\u00e3o e tratamento de valores nulos","text":"<p>O primeiro passo para o pr\u00e9-processamento \u00e9 identificar e tratar valores nulos na base.</p> <pre><code>print(df.isna().sum())\n</code></pre> <p>Executando a linha de c\u00f3digo acima para o dataframe contendo os dados da base, foi poss\u00edvel identificar que n\u00e3o h\u00e1 valores nulos na base.</p>"},{"location":"k-means/main/#2-passo-remocao-de-colunas-desimportantes","title":"2\u00b0 Passo: Remo\u00e7\u00e3o de colunas desimportantes","text":"<p>Em seguida, colunas que n\u00e3o s\u00e3o importantes para a predi\u00e7\u00e3o ser\u00e3o removidas do dataframe. Essas colunas s\u00e3o <code>Booking_ID</code> e <code>date of reservation</code>. A forma que essa exclus\u00e3o foi feita est\u00e1 representada abaixo:</p> <pre><code>df = df.drop(columns=[\"Booking_ID\", \"date of reservation\"])\n</code></pre>"},{"location":"k-means/main/#3-passo-codificacao-de-variaveis-categoricas","title":"3\u00b0 Passo: Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas","text":"<p>O terceiro passo se consiste na codifica\u00e7\u00e3o das vari\u00e1veis categ\u00f3ricas. Essas s\u00e3o: <code>type of meal</code>, <code>room type</code> e <code>market segment type</code>. Considerando a forma como a t\u00e9cnica do KNN funciona, calculando a dist\u00e2ncia euclidiana entre pontos para predizer, a t\u00e9cnica de label encoding seria ruim, pois os valores num\u00e9ricos arbitr\u00e1rios poderiam criar dist\u00e2ncias falsas entre as categorias. Por isso, utilizaremos a t\u00e9cnica de One-Hot Encoding para codificar essas vari\u00e1veis, utilizando o OneHotEncoder() do <code>scikit-learn</code>.</p> <pre><code>from sklearn.preprocessing import OneHotEncoder\n\ncategorical_cols = [\"type of meal\", \"room type\", \"market segment type\"]\n\nX = df.drop(\"booking status\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nencoder = OneHotEncoder(drop=\"first\", sparse_output=False)\nencoder.fit(X_train[categorical_cols])\n\nX_train_encoded = encoder.transform(X_train[categorical_cols])\nX_test_encoded = encoder.transform(X_test[categorical_cols])\n</code></pre>"},{"location":"k-means/main/#4-passo-padronizacao-das-features-numericas","title":"4\u00b0 Passo: Padroniza\u00e7\u00e3o das features num\u00e9ricas","text":"<p>Em seguida, \u00e9 necess\u00e1ria a padroniza\u00e7\u00e3o das features num\u00e9ricas na base. Ao inv\u00e9s da normaliza\u00e7\u00e3o, ser\u00e1 utilizada a t\u00e9cnica de padroniza\u00e7\u00e3o devido aos outliers nas features num\u00e9ricas, principalmente as vari\u00e1veis <code>lead time</code> e <code>average price</code>, que desbalanceariam o c\u00e1lculo de dist\u00e2ncias se apenas normalizadas. Para a padroniza\u00e7\u00e3o, utilizaremos o StandardScaler() do <code>scikit-learn</code>.</p> <pre><code>from sklearn.preprocessing import StandardScaler\n\nnumeric_cols = [\"number of adults\", \"number of children\", \"number of weekend nights\", \n                \"number of week nights\", \"lead time\", \"P-C\", \"P-not-C\", \n                \"average price\", \"special requests\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n</code></pre>"},{"location":"k-means/main/#5-passo-codificacao-da-variavel-alvo","title":"5\u00b0 Passo: Codifica\u00e7\u00e3o da vari\u00e1vel alvo","text":"<p>Por fim, vamos codificar a vari\u00e1vel alvo <code>booking status</code> utilizando a t\u00e9cnica de label encoding. Ou seja, ap\u00f3s esse passo, \"Not_Canceled\" vai assumir o valor 1 e \"Canceled\" o valor 0. Aqui, essa t\u00e9cnica pode ser utilizada, pois essa \u00e9 a vari\u00e1vel alvo, e n\u00e3o ser\u00e1 utilizada no c\u00e1lculo das dist\u00e2ncias. Para codificar, utilizaremos o LabelEncoder() do <code>scikit-learn</code>.</p> <pre><code>from sklearn.preprocessing import LabelEncoder\n\nl_encoder = LabelEncoder()\ny = l_encoder.fit_transform(df[\"booking status\"])\n</code></pre>"},{"location":"k-means/main/#divisao-dos-dados","title":"Divis\u00e3o dos dados","text":"<p>Essa etapa ser\u00e1 realizada antes do pr\u00e9-processamento, e apenas o conjunto de treino resultante desta divis\u00e3o ser\u00e1 base para o pr\u00e9-processamento.</p> <ul> <li> <p>Conjunto de Treino: Utilizado para ensinar o modelo a reconhecer padr\u00f5es</p> </li> <li> <p>Conjunto de Teste: Utilizado para avaliar o desempenho do modelo com dados ainda n\u00e3o vistos</p> </li> </ul> <p>Para realizar a divis\u00e3o, foi utilizada a fun\u00e7\u00e3o train_test_split() do <code>scikit-learn</code>. Os par\u00e2metros utilizados s\u00e3o:</p> <ul> <li> <p>test_size=0.2: Define que 20% dos dados ser\u00e3o utilizados para teste, enquanto o restante ser\u00e1 usado para treino.</p> </li> <li> <p>random_state=42: Par\u00e2metro que controla o gerador de n\u00famero aleat\u00f3rios utilizado para sortear os dados antes de separ\u00e1-los. Garante reprodutibilidade.</p> </li> <li> <p>stratify=y: Esse atributo definido como y \u00e9 essencial devido \u00e0 natureza da coluna <code>booking status</code>. Com essa defini\u00e7\u00e3o, ser\u00e1 mantida a mesma propor\u00e7\u00e3o das categorias em ambos os conjuntos, reduzindo o vi\u00e9s.</p> </li> </ul> Sa\u00eddaC\u00f3digo <p>Treino: 29028 amostras</p> <p>Teste: 7257 amostras</p> <p>Propor\u00e7\u00e3o: 80.0% treino, 20.0% teste</p> <p>Distribui\u00e7\u00e3o das classes - </p> <p>Treino:</p> booking status count Not_Canceled 19517 Canceled 9511 <p>Teste:</p> booking status count Not_Canceled 4879 Canceled 2378 <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\ndf = df.drop(columns=[\"Booking_ID\", \"date of reservation\"])\n\nX = df.drop(\"booking status\", axis=1)\ny = df[\"booking status\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nprint(f\"Treino: {X_train.shape[0]} amostras\\n\")\nprint(f\"Teste: {X_test.shape[0]} amostras\\n\")\nprint(f\"Propor\u00e7\u00e3o: {X_train.shape[0]/X.shape[0]*100:.1f}% treino, {X_test.shape[0]/X.shape[0]*100:.1f}% teste\\n\")\n\nprint(\"Distribui\u00e7\u00e3o das classes - \\n\")\nprint(\"Treino:\\n\")\nprint(y_train.value_counts().to_markdown(), \"\\n\")\nprint(\"Teste:\\n\")\nprint(y_test.value_counts().to_markdown(), \"\\n\")\n</code></pre> <p>Esta divis\u00e3o adequada \u00e9 de extrema import\u00e2ncia, pois ajuda a evitar overfitting.</p>"},{"location":"k-means/main/#etapa-3-treinamento-dos-modelos","title":"Etapa 3 - Treinamento dos Modelos","text":"<p>Agora, ser\u00e1 realizado o treinamento do modelo. O objetivo dessa etapa \u00e9 ensinar o algoritmo a reconhecer padr\u00f5es nos dados que s\u00e3o fornecidos, e determinar se uma reserva ser\u00e1, ou n\u00e3o, cancelada de acordo com os dados das outras vari\u00e1veis na base. A t\u00e9cnica utilizada, desta vez, ser\u00e1 do K-Means, que se consiste na segrega\u00e7\u00e3o dos dados em torno de centros, criando clusters.</p>"},{"location":"k-means/main/#resultado-dos-treinamentos","title":"Resultado dos treinamentos","text":"K-MeansC\u00f3digo"},{"location":"k-means/main/#etapa-4-avaliacao-dos-modelos","title":"Etapa 4 - Avalia\u00e7\u00e3o dos modelos","text":""},{"location":"k-means/main/#matriz-de-confusao","title":"Matriz de confus\u00e3o","text":"<p>Agora, vamos observar a matriz de confus\u00e3o do modelo. A matriz de confus\u00e3o consegue nos oferecer diversas m\u00e9tricas de qualidade do modelo, como o n\u00famero de previs\u00f5es correta para positivos e negativos, os falso positivos, falso negativos, a precis\u00e3o, especificidade, dentre outras m\u00e9tricas.</p> Matriz de confus\u00e3o - Modelo 2C\u00f3digo"},{"location":"k-means/main/#etapa-5-relatorio-final","title":"Etapa 5 - Relat\u00f3rio Final","text":""},{"location":"knn/main/","title":"Projeto 2 - KNN","text":""},{"location":"knn/main/#modelo-de-machine-learning-knn","title":"Modelo de Machine Learning - KNN","text":"<p>Para esse projeto, foi utilizado um dataset obtido no Kaggle. Os dados usados podem ser baixados aqui.</p>"},{"location":"knn/main/#objetivo","title":"Objetivo","text":"<p>O dataset utilizado possui informa\u00e7\u00f5es sobre reservas em um hotel, e foi criado justamente para a cria\u00e7\u00e3o de modelos de machine learning com o objetivo de prever se um agendamento ser\u00e1, ou n\u00e3o, cancelado.</p> <p>Os dados originais para a cria\u00e7\u00e3o desse dataset foram obtidos em um artigo de dados, no site Science Direct. O artigo em quest\u00e3o foi escrito por Nuno Antonio, Ana de Almeida e Luis Nunes, e cont\u00e9m uma quantidade maior de dados do que a sua vers\u00e3o derivada do Kaggle, que estou utilizando para este projeto.</p>"},{"location":"knn/main/#workflow","title":"Workflow","text":"<p>Os pontos \"etapas\" s\u00e3o o passo-a-passo da realiza\u00e7\u00e3o do projeto.</p>"},{"location":"knn/main/#etapa-1-exploracao-de-dados","title":"Etapa 1 - Explora\u00e7\u00e3o de Dados","text":"<p>Primeiramente, deve ser feita a explora\u00e7\u00e3o dos dados da base, com o objetivo de compreender a forma como s\u00e3o estruturados os dados, sua natureza e poss\u00edvel signific\u00e2ncia para o modelo de predi\u00e7\u00e3o.</p> <p>O dataset \u00e9 composto por 36285 linhas e 17 colunas, com cada linha representando uma reserva distinta. Essa verifica\u00e7\u00e3o p\u00f4de ser feita com as linhas de c\u00f3digo abaixo;</p> Sa\u00eddaC\u00f3digo <p>(36285, 17)</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nprint(df.shape)\n</code></pre>"},{"location":"knn/main/#colunas-do-dataset","title":"Colunas do dataset","text":"Coluna Tipo Descri\u00e7\u00e3o Booking_ID String Identificador \u00fanico da reserva number of adults Inteiro N\u00famero de adultos presentes na reserva number of children Inteiro N\u00famero de crian\u00e7as presentes na reserva number of weekend nights Inteiro Quantidade de noites em finais de semana reservadas number of week nights Inteiro Quantidade de noites em dias de semana reservadas type of meal String Plano de alimenta\u00e7\u00e3o escolhido pelo cliente car parking space Inteiro Vari\u00e1vel bin\u00e1ria que indica se um estacionamento de carro foi pedido ou incluso na reserva room type String Tipo de quarto reservado lead time Inteiro N\u00famero de dias entre a data da reserva e a data de chegada do cliente market segment type String Tipo de segmento do mercado associado \u00e0 reserva repeated Inteiro Vari\u00e1vel bin\u00e1ria que indica se a reserva \u00e9, ou n\u00e3o, repetida P-C Inteiro N\u00famero de reservas anteriores que foram canceladas pelo cliente antes do agendamento atual P-not-C Inteiro N\u00famero de reservas anteriores que n\u00e3o foram canceladas pelo cliente antes do agendamento atual average price Float Pre\u00e7o m\u00e9dio associado \u00e0 reserva special requests Inteiro N\u00famero de pedidos especiais feitos pelo convidado(a) date of reservation String Data da reserva booking status String Status da reserva (cancelada ou n\u00e3o cancelada)"},{"location":"knn/main/#visualizacoes-das-variaveis","title":"Visualiza\u00e7\u00f5es das vari\u00e1veis","text":"<p>Em seguida, \u00e9 essencial realizar gr\u00e1ficos para visualizar como cada uma das vari\u00e1veis se comportam, com o objetivo de entender melhor a base da dados.</p> <p>Est\u00e1 se\u00e7\u00e3o ser\u00e1 divida para cada tipo de vari\u00e1vel, entre vari\u00e1veis quantitativas discretas, quantitativas cont\u00ednuas, qualitativas categ\u00f3ricas, bin\u00e1rias e, por fim, a vari\u00e1vel alvo.</p>"},{"location":"knn/main/#variaveis-quantitativas-discretas","title":"Vari\u00e1veis Quantitativas Discretas","text":"number of adultsnumber of childrennumber of weekend nightsnumber of week nightslead timeP-CP-not-Cspecial requests Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:35.026551 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"number of adults\"].value_counts().sort_index().plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o do N\u00famero de Adultos por Reserva - Barras\")\nplt.xlabel(\"N\u00famero de Adultos\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:35.226835 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"number of children\"].value_counts().sort_index().plot(kind=\"bar\", color=\"lightcoral\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o do N\u00famero de Crian\u00e7as por Reserva - Barras\")\nplt.xlabel(\"N\u00famero de Crian\u00e7as\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:35.446231 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"number of weekend nights\"].value_counts().sort_index().plot(kind=\"bar\", color=\"lightgreen\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o de Noites de Fim de Semana por Reserva - Barras\")\nplt.xlabel(\"N\u00famero de Noites de Fim de Semana\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:35.671533 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"number of week nights\"].value_counts().sort_index().plot(kind=\"bar\", color=\"gold\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o de Noites de Dias de Semana por Reserva - Barras\")\nplt.xlabel(\"N\u00famero de Noites de Dias de Semana\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:35.949403 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\nlead_time_bins = pd.cut(df[\"lead time\"], bins=8)\nlead_time_bins.value_counts().sort_index().plot(kind=\"bar\", color=\"coral\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o do Lead Time (dias entre reserva e chegada) - Barras\")\nplt.xlabel(\"Intervalo de Dias\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=45)\nplt.grid(axis=\"y\", alpha=0.3)\nplt.tight_layout()\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:36.165083 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"P-C\"].value_counts().sort_index().plot(kind=\"bar\", color=\"orange\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o de Reservas Anteriormente Canceladas (P-C) - Barras\")\nplt.xlabel(\"N\u00famero de Reservas Anteriormente Canceladas\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:36.371611 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"P-not-C\"], bins=15, edgecolor=\"black\", alpha=0.7, color=\"blue\")\nplt.title(\"Distribui\u00e7\u00e3o de Reservas Anteriormente N\u00e3o Canceladas (P-not-C) - Histograma\")\nplt.xlabel(\"N\u00famero de Reservas Anteriormente N\u00e3o Canceladas\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:36.593461 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\ndf[\"special requests\"].value_counts().sort_index().plot(kind=\"bar\", color=\"purple\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o de Pedidos Especiais por Reserva - Barras\")\nplt.xlabel(\"N\u00famero de Pedidos Especiais\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"knn/main/#variavel-quantitativa-continua-average-price","title":"Vari\u00e1vel Quantitativa Cont\u00ednua <code>average price</code>","text":"Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:36.798567 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"average price\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"red\")\nplt.title(\"Distribui\u00e7\u00e3o do Pre\u00e7o M\u00e9dio das Reservas - Histograma\")\nplt.xlabel(\"Pre\u00e7o M\u00e9dio\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"knn/main/#variaveis-categoricas","title":"Vari\u00e1veis Categ\u00f3ricas","text":"type of mealroom typemarket segment type Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:37.022262 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 8))\ndf[\"type of meal\"].value_counts().plot(kind=\"bar\", color=\"lightseagreen\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o dos Tipos de Refei\u00e7\u00e3o - Barras\")\nplt.xlabel(\"Tipo de Refei\u00e7\u00e3o\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=45)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:37.217521 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 8))\ndf[\"room type\"].value_counts().plot(kind=\"bar\", color=\"mediumpurple\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o dos Tipos de Quarto - Barras\")\nplt.xlabel(\"Tipo de Quarto\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=45)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:37.416529 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nplt.figure(figsize=(10, 8))\ndf[\"market segment type\"].value_counts().plot(kind=\"bar\", color=\"salmon\", edgecolor=\"black\")\nplt.title(\"Distribui\u00e7\u00e3o dos Segmentos de Mercado - Barras\")\nplt.xlabel(\"Segmento de Mercado\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=45)\nplt.grid(axis=\"y\", alpha=0.3)\n\nax = plt.gca()\nfor p in ax.patches:\n    ax.annotate(f\"{int(p.get_height())}\", \n                (p.get_x() + p.get_width()/2., p.get_height()),\n                ha=\"center\", va=\"bottom\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"knn/main/#variaveis-binarias","title":"Vari\u00e1veis Bin\u00e1rias","text":"car parking spacerepeated Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:37.599384 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nlabels = [\"Sem estacionamento\", \"Com estacionamento\"]  \nvalues = df[\"car parking space\"].value_counts()\n\nplt.figure(figsize=(10, 8))\nplt.pie(values, labels=labels, autopct=lambda p: f\"{int(p * sum(values) / 100)}\", colors=[\"lightblue\", \"lightcoral\"])\nplt.title(\"Distribui\u00e7\u00e3o do Status das Reservas - Pizza\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:37.771311 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nlabels = [\"N\u00e3o Repetido\", \"Repetido\"]  \nvalues = df[\"repeated\"].value_counts()\n\nplt.figure(figsize=(10, 8))\nplt.pie(values, labels=labels, autopct=lambda p: f\"{int(p * sum(values) / 100)}\", colors=[\"lightgreen\", \"lightyellow\"])\nplt.title(\"Distribui\u00e7\u00e3o do Status das Reservas - Pizza\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"knn/main/#variavel-alvo-booking-status","title":"Vari\u00e1vel Alvo <code>booking status</code>","text":"Gr\u00e1ficoC\u00f3digo 2025-09-28T18:11:37.943141 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\nlabels = [\"Cancelado\", \"N\u00e3o Cancelado\"]  \nvalues = df[\"booking status\"].value_counts()\n\nplt.figure(figsize=(10, 8))\nplt.pie(values, labels=labels, autopct=lambda p: f\"{int(p * sum(values) / 100)}\", colors=[\"lightcoral\", \"lightgreen\"])\nplt.title(\"Distribui\u00e7\u00e3o do Status das Reservas - Pizza\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> <p>Atrav\u00e9s das an\u00e1lises, foi poss\u00edvel alcan\u00e7ar uma compreens\u00e3o mais aprofundada do funcionamento de cada uma das vari\u00e1veis no dataset, al\u00e9m de haver insights valiosos nesses gr\u00e1ficos. Esses dados ser\u00e3o essenciais para a escolha das vari\u00e1veis que ser\u00e3o utilizadas no modelo.</p>"},{"location":"knn/main/#etapa-2-pre-processamento-e-divisao-de-dados","title":"Etapa 2 - Pr\u00e9-processamento e Divis\u00e3o de Dados","text":"<p>Neste projeto, ap\u00f3s um estudo do pr\u00e9-processamento e divis\u00e3o de dados, foram considerados dois modelos distintos de pr\u00e9-processamento. O primeiro modelo faz, primeiro, o pr\u00e9-processamento, utilizando todo o dataset para treinar o modelo de predi\u00e7\u00e3o. O segundo modelo cria o pr\u00e9-processamento apenas com os dados de treinamento, evitando que o modelo tenha acesso indireto aos dados de teste, evitando data leakage.</p> <p>O primeiro modelo utiliza os dados de teste para realizar a padroniza\u00e7\u00e3o e substitui\u00e7\u00e3o de valores nulos no dataset inteiro, fazendo com que, indiretamente, o modelo tenha acesso aos dados de teste. Esse problema pode afetar a acur\u00e1cia do modelo com enviesamento, fazendo com que sua efic\u00e1cia real seja diferente da testada. O segundo modelo trata os dados de teste como dados que nunca foram acessados pelo modelo. O pr\u00e9-processamento, depois de feito a partir dos dados de treino, ser\u00e1 aplicado aos dados de teste, inserindo-os no mesmo dom\u00ednio do modelo para que possam ser realizadas predi\u00e7\u00f5es. A hip\u00f3tese principal \u00e9 de que a acur\u00e1cia do segundo modelo ser\u00e1 um pouco menor, mas o modelo ter\u00e1 menos vi\u00e9s.</p> <p>Abaixo, est\u00e3o o diagramas de sequ\u00eancia representando cada modelo:</p>"},{"location":"knn/main/#modelo-1-pre-processamento-divisao-dos-dados","title":"Modelo 1 - Pr\u00e9-processamento -&gt; Divis\u00e3o dos Dados","text":"<pre><code>flowchart TD\n    A[Explora\u00e7\u00e3o de Dados] --&gt; B[Pr\u00e9-processamento]\n    B --&gt; C{Divis\u00e3o dos Dados}\n    C --&gt;|80% dos dados| D[Treino] --&gt; F[Treinamento do modelo]\n    C --&gt;|20% dos dados| E[Teste] --&gt; G[Avalia\u00e7\u00e3o do modelo]\n    F --&gt; G</code></pre>"},{"location":"knn/main/#modelo-2-divisao-dos-dados-pre-processamento","title":"Modelo 2 Divis\u00e3o dos Dados -&gt; Pr\u00e9-processamento","text":"<pre><code>flowchart TD\n    A[Explora\u00e7\u00e3o de Dados] --&gt; B{Divis\u00e3o dos Dados}\n    B --&gt;|Teste&lt;br&gt;20% dos dados| PTest[Pr\u00e9-processamento]\n    B --&gt;|Treino&lt;br&gt;80% dos dados| PTrain[Pr\u00e9-processamento]\n    PTrain --&gt; Train[Treinamento]\n    Train --&gt; G\n    PTest --&gt; G[Avalia\u00e7\u00e3o do modelo]</code></pre> <p>Nos dois modelos, o pr\u00e9-processamento \u00e9 o mesmo. O que muda \u00e9 o conjunto de dados em que ele \u00e9 aplicado, sendo aplicado em todo o dataset no modelo 1 e apenas no conjunto de treino no modelo 2.</p>"},{"location":"knn/main/#1-passo-identificacao-e-tratamento-de-valores-nulos","title":"1\u00b0 Passo: Identifica\u00e7\u00e3o e tratamento de valores nulos","text":"<p>O primeiro passo para o pr\u00e9-processamento \u00e9 identificar e tratar valores nulos na base.</p> <pre><code>print(df.isna().sum())\n</code></pre> <p>Executando a linha de c\u00f3digo acima para o dataframe contendo os dados da base, foi poss\u00edvel identificar que n\u00e3o h\u00e1 valores nulos na base.</p>"},{"location":"knn/main/#2-passo-remocao-de-colunas-desimportantes","title":"2\u00b0 Passo: Remo\u00e7\u00e3o de colunas desimportantes","text":"<p>Em seguida, colunas que n\u00e3o s\u00e3o importantes para a predi\u00e7\u00e3o ser\u00e3o removidas do dataframe. Essas colunas s\u00e3o <code>Booking_ID</code> e <code>date of reservation</code>. A forma que essa exclus\u00e3o foi feita est\u00e1 representada abaixo:</p> <pre><code>df = df.drop(columns=[\"Booking_ID\", \"date of reservation\"])\n</code></pre>"},{"location":"knn/main/#3-passo-codificacao-de-variaveis-categoricas","title":"3\u00b0 Passo: Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas","text":"<p>O terceiro passo se consiste na codifica\u00e7\u00e3o das vari\u00e1veis categ\u00f3ricas. Essas s\u00e3o: <code>type of meal</code>, <code>room type</code> e <code>market segment type</code>. Considerando a forma como a t\u00e9cnica do KNN funciona, calculando a dist\u00e2ncia euclidiana entre pontos para predizer, a t\u00e9cnica de label encoding seria ruim, pois os valores num\u00e9ricos arbitr\u00e1rios poderiam criar dist\u00e2ncias falsas entre as categorias. Por isso, utilizaremos a t\u00e9cnica de One-Hot Encoding para codificar essas vari\u00e1veis, utilizando o OneHotEncoder() do <code>scikit-learn</code>.</p> <p>Modelo 1:</p> <pre><code>from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder()\ncategorical_cols = [\"type of meal\", \"room type\", \"market segment type\"]\n\nX = df.drop(\"booking status\", axis=1)\n\nX_encoded = encoder.fit_transform(X[categorical_cols])\nencoded_df = pd.DataFrame(X_encoded.toarray(), columns=encoder.get_feature_names_out(categorical_cols), index=X.index)\n\nX = pd.concat([X.drop(columns=categorical_cols), encoded_df], axis=1)\n</code></pre> <p>Modelo 2:</p> <pre><code>from sklearn.preprocessing import OneHotEncoder\n\ncategorical_cols = [\"type of meal\", \"room type\", \"market segment type\"]\n\nX = df.drop(\"booking status\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nencoder = OneHotEncoder(drop=\"first\", sparse_output=False)\nencoder.fit(X_train[categorical_cols])\n\nX_train_encoded = encoder.transform(X_train[categorical_cols])\nX_test_encoded = encoder.transform(X_test[categorical_cols])\n</code></pre>"},{"location":"knn/main/#4-passo-padronizacao-das-features-numericas","title":"4\u00b0 Passo: Padroniza\u00e7\u00e3o das features num\u00e9ricas","text":"<p>Em seguida, \u00e9 necess\u00e1ria a padroniza\u00e7\u00e3o das features num\u00e9ricas na base. Ao inv\u00e9s da normaliza\u00e7\u00e3o, ser\u00e1 utilizada a t\u00e9cnica de padroniza\u00e7\u00e3o devido aos outliers nas features num\u00e9ricas, principalmente as vari\u00e1veis <code>lead time</code> e <code>average price</code>, que desbalanceariam o c\u00e1lculo de dist\u00e2ncias se apenas normalizadas. Para a padroniza\u00e7\u00e3o, utilizaremos o StandardScaler() do <code>scikit-learn</code>.</p> <p>Modelo 1:</p> <pre><code>from sklearn.preprocessing import OneHotEncoder\n\nscaler = StandardScaler()\nnumeric_cols = [\"number of adults\", \"number of children\", \"number of weekend nights\", \n                \"number of week nights\", \"lead time\", \"P-C\", \"P-not-C\", \n                \"average price\", \"special requests\"]\n\nX = df.drop(\"booking status\", axis=1)\n\nfor col in numeric_cols:\n    X[col] = scaler.fit_transform(X[[col]])\n</code></pre> <p>Modelo 2:</p> <pre><code>from sklearn.preprocessing import StandardScaler\n\nnumeric_cols = [\"number of adults\", \"number of children\", \"number of weekend nights\", \n                \"number of week nights\", \"lead time\", \"P-C\", \"P-not-C\", \n                \"average price\", \"special requests\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n</code></pre>"},{"location":"knn/main/#5-passo-codificacao-da-variavel-alvo","title":"5\u00b0 Passo: Codifica\u00e7\u00e3o da vari\u00e1vel alvo","text":"<p>Por fim, vamos codificar a vari\u00e1vel alvo <code>booking status</code> utilizando a t\u00e9cnica de label encoding. Ou seja, ap\u00f3s esse passo, \"Not_Canceled\" vai assumir o valor 1 e \"Canceled\" o valor 0. Aqui, essa t\u00e9cnica pode ser utilizada, pois essa \u00e9 a vari\u00e1vel alvo, e n\u00e3o ser\u00e1 utilizada no c\u00e1lculo das dist\u00e2ncias. Para codificar, utilizaremos o LabelEncoder() do <code>scikit-learn</code>.</p> <p>Modelo 1 e 2:</p> <pre><code>from sklearn.preprocessing import LabelEncoder\n\nl_encoder = LabelEncoder()\ny = l_encoder.fit_transform(df[\"booking status\"])\n</code></pre>"},{"location":"knn/main/#divisao-dos-dados","title":"Divis\u00e3o dos dados","text":"<p>Como explicado anteriormente, essa etapa ser\u00e1 realizada em momentos distintos dependendo do modelo utilizado. No primeiro modelo, esta etapa vem depois de todo o pr\u00e9-processamento. No segundo modelo, esta etapa vem antes do pr\u00e9-processamento.</p> <ul> <li> <p>Conjunto de Treino: Utilizado para ensinar o modelo a reconhecer padr\u00f5es</p> </li> <li> <p>Conjunto de Teste: Utilizado para avaliar o desempenho do modelo com dados ainda n\u00e3o vistos</p> </li> </ul> <p>Para realizar a divis\u00e3o, foi utilizada a fun\u00e7\u00e3o train_test_split() do <code>scikit-learn</code>. Os par\u00e2metros utilizados s\u00e3o:</p> <ul> <li> <p>test_size=0.2: Define que 20% dos dados ser\u00e3o utilizados para teste, enquanto o restante ser\u00e1 usado para treino.</p> </li> <li> <p>random_state=42: Par\u00e2metro que controla o gerador de n\u00famero aleat\u00f3rios utilizado para sortear os dados antes de separ\u00e1-los. Garante reprodutibilidade.</p> </li> <li> <p>stratify=y: Esse atributo definido como y \u00e9 essencial devido \u00e0 natureza da coluna <code>booking status</code>. Com essa defini\u00e7\u00e3o, ser\u00e1 mantida a mesma propor\u00e7\u00e3o das categorias em ambos os conjuntos, reduzindo o vi\u00e9s.</p> </li> </ul> Sa\u00eddaC\u00f3digo <p>Treino: 29028 amostras</p> <p>Teste: 7257 amostras</p> <p>Propor\u00e7\u00e3o: 80.0% treino, 20.0% teste</p> <p>Distribui\u00e7\u00e3o das classes - </p> <p>Treino:</p> booking status count Not_Canceled 19517 Canceled 9511 <p>Teste:</p> booking status count Not_Canceled 4879 Canceled 2378 <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\ndf = df.drop(columns=[\"Booking_ID\", \"date of reservation\"])\n\nX = df.drop(\"booking status\", axis=1)\ny = df[\"booking status\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nprint(f\"Treino: {X_train.shape[0]} amostras\\n\")\nprint(f\"Teste: {X_test.shape[0]} amostras\\n\")\nprint(f\"Propor\u00e7\u00e3o: {X_train.shape[0]/X.shape[0]*100:.1f}% treino, {X_test.shape[0]/X.shape[0]*100:.1f}% teste\\n\")\n\nprint(\"Distribui\u00e7\u00e3o das classes - \\n\")\nprint(\"Treino:\\n\")\nprint(y_train.value_counts().to_markdown(), \"\\n\")\nprint(\"Teste:\\n\")\nprint(y_test.value_counts().to_markdown(), \"\\n\")\n</code></pre> <p>Esta divis\u00e3o adequada \u00e9 de extrema import\u00e2ncia, pois ajuda a evitar overfitting.</p>"},{"location":"knn/main/#etapa-3-treinamento-dos-modelos","title":"Etapa 3 - Treinamento dos Modelos","text":"<p>Agora, ser\u00e1 realizado o treinamento dos modelos. O objetivo dessa etapa \u00e9 ensinar o algoritmo a reconhecer padr\u00f5es nos dados que s\u00e3o fornecidos, e determinar se uma reserva ser\u00e1, ou n\u00e3o, cancelada de acordo com os dados das outras vari\u00e1veis na base.</p> <p>Para visualizar a efic\u00e1cia dos modelos, foi aplicado um PCA (Principal Component Analysis) para definir as melhores vari\u00e1veis a serem visualizadas. Al\u00e9m disso, foram feitas matrizes de confus\u00e3o dos dois modelos.</p>"},{"location":"knn/main/#resultado-dos-treinamentos","title":"Resultado dos treinamentos","text":"<p>Modelo 1:</p> KNN - Modelo 1C\u00f3digo <p></p> Acur\u00e1cia: 0.8541 <p></p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.decomposition import PCA\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\nl_encoder = LabelEncoder()\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\ndf = df.drop(columns=[\"Booking_ID\", \"date of reservation\"])\n\nnumeric_cols = [\"number of adults\", \"number of children\", \"number of weekend nights\", \n                \"number of week nights\", \"lead time\", \"P-C\", \"P-not-C\", \n                \"average price\", \"special requests\"]\n\ncategorical_cols = [\"type of meal\", \"room type\", \"market segment type\"]\n\nX = df.drop(\"booking status\", axis=1)\ny = l_encoder.fit_transform(df[\"booking status\"])\n\nfor col in numeric_cols:\n    X[col] = scaler.fit_transform(X[[col]])\n\nX_encoded = encoder.fit_transform(X[categorical_cols])\n\nencoded_df = pd.DataFrame(X_encoded.toarray(), columns=encoder.get_feature_names_out(categorical_cols), index=X.index)\n\nX = pd.concat([X.drop(columns=categorical_cols), encoded_df], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.4f}&lt;br&gt;\")\n\n# Visualiza\u00e7\u00e3o do KNN \n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\nprint(\"Variance explained by each component:\", pca.explained_variance_ratio_)\n\nX_train_pca, X_test_pca, _, _ = train_test_split(X_pca, y, test_size=0.2, random_state=42)\nknn_pca = KNeighborsClassifier(n_neighbors=3)\nknn_pca.fit(X_train_pca, y_train)\n\nh = .05\nx_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\ny_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\nnp.arange(y_min, y_max, h))\n\nZ = knn_pca.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.figure(figsize=(10, 7))\nplt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\nsns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette=\"coolwarm\", edgecolor=\"k\", s=60)\nplt.title(\"KNN com PCA do Modelo 1)\")\nplt.xlabel(\"Componente Principal 1\")\nplt.ylabel(\"Componente Principal 2\")\nplt.legend(title=\"Booking status\")\n\nplt.savefig(\"docs/images/knn_modelo1.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre> <p>Modelo 2:</p> KNN - Modelo 2C\u00f3digo <p></p> Acur\u00e1cia: 0.8521 <p></p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.decomposition import PCA\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\nl_encoder = LabelEncoder()\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\ndf = df.drop(columns=[\"Booking_ID\", \"date of reservation\"])\n\nnumeric_cols = [\"number of adults\", \"number of children\", \"number of weekend nights\", \n                \"number of week nights\", \"lead time\", \"P-C\", \"P-not-C\", \n                \"average price\", \"special requests\"]\n\ncategorical_cols = [\"type of meal\", \"room type\", \"market segment type\"]\n\nX = df.drop(\"booking status\", axis=1)\ny = l_encoder.fit_transform(df[\"booking status\"])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler.fit(X_train[numeric_cols])\nencoder.fit(X_train[categorical_cols])\n\nX_train_scaled = scaler.transform(X_train[numeric_cols])\nX_test_scaled = scaler.transform(X_test[numeric_cols])\n\nX_train_encoded = encoder.transform(X_train[categorical_cols]).toarray()\nX_test_encoded = encoder.transform(X_test[categorical_cols]).toarray()\n\nX_train_final = np.concatenate([X_train_scaled, X_train_encoded], axis=1)\nX_test_final = np.concatenate([X_test_scaled, X_test_encoded], axis=1)\n\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train_final, y_train)\npredictions = knn.predict(X_test_final)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.4f} &lt;br&gt;\")\n\n# Visualiza\u00e7\u00e3o do KNN \n\npca = PCA(n_components=2)\nX_train_pca = pca.fit_transform(X_train_final)\nX_test_pca = pca.transform(X_test_final)\nprint(\"Variance explained by each component:\", pca.explained_variance_ratio_)\n\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train_pca, y_train)\npredictions = knn.predict(X_test_pca)\n\nplt.figure(figsize=(12, 8))\n\nh = 0.05\nx_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\ny_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu, alpha=0.3)\n\nsns.scatterplot(x=X_train_pca[:, 0], y=X_train_pca[:, 1], hue=y_train,\n                palette=\"deep\", edgecolor=\"k\", s=80)\nsns.scatterplot(x=X_test_pca[:, 0], y=X_test_pca[:, 1], hue=y_test,\n                palette=\"deep\", edgecolor=\"k\", marker=\"X\", s=120)\n\nplt.xlabel(\"Componente Principal 1\")\nplt.ylabel(\"Componente Principal 2\")\nplt.title(\"KNN com PCA do Modelo 2\")\nplt.legend()\n\nplt.savefig(\"docs/images/knn_modelo2.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre>"},{"location":"knn/main/#etapa-4-avaliacao-dos-modelos","title":"Etapa 4 - Avalia\u00e7\u00e3o dos modelos","text":""},{"location":"knn/main/#matrizes-de-confusao","title":"Matrizes de confus\u00e3o","text":"<p>Primeiramente, vamos observar as matrizes de confus\u00e3o de ambos os modelos. A matriz de confus\u00e3o consegue nos oferecer diversas m\u00e9tricas de qualidade do modelo, como o n\u00famero de previs\u00f5es correta para positivos e negativos, os falso positivos, falso negativos, a precis\u00e3o, especificidade, dentre outras m\u00e9tricas.</p> <p>Modelo 1:</p> Matriz de confus\u00e3o - Modelo 1C\u00f3digo <p></p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\nl_encoder = LabelEncoder()\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\ndf = df.drop(columns=[\"Booking_ID\", \"date of reservation\"])\n\nnumeric_cols = [\"number of adults\", \"number of children\", \"number of weekend nights\", \n                \"number of week nights\", \"lead time\", \"P-C\", \"P-not-C\", \n                \"average price\", \"special requests\"]\n\ncategorical_cols = [\"type of meal\", \"room type\", \"market segment type\"]\n\nX = df.drop(\"booking status\", axis=1)\ny = l_encoder.fit_transform(df[\"booking status\"])\n\nfor col in numeric_cols:\n    X[col] = scaler.fit_transform(X[[col]])\n\nX_encoded = encoder.fit_transform(X[categorical_cols])\n\nencoded_df = pd.DataFrame(X_encoded.toarray(), columns=encoder.get_feature_names_out(categorical_cols), index=X.index)\n\nX = pd.concat([X.drop(columns=categorical_cols), encoded_df], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\n\ncm = confusion_matrix(y_test, predictions)\n\nplt.figure(figsize=(6,4))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=l_encoder.classes_, yticklabels=l_encoder.classes_)\nplt.xlabel(\"Predito\")\nplt.ylabel(\"Real\")\nplt.title(\"Matriz de Confus\u00e3o - KNN Modelo 1\")\n\nplt.savefig(\"docs/images/cm_knn_modelo1.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre> <p>Modelo 2:</p> Matriz de confus\u00e3o - Modelo 2C\u00f3digo <p></p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\nl_encoder = LabelEncoder()\n\ndf = pd.read_csv(\"docs/knn/booking.csv\")\n\ndf = df.drop(columns=[\"Booking_ID\", \"date of reservation\"])\n\nnumeric_cols = [\"number of adults\", \"number of children\", \"number of weekend nights\", \n                \"number of week nights\", \"lead time\", \"P-C\", \"P-not-C\", \n                \"average price\", \"special requests\"]\n\ncategorical_cols = [\"type of meal\", \"room type\", \"market segment type\"]\n\nX = df.drop(\"booking status\", axis=1)\ny = l_encoder.fit_transform(df[\"booking status\"])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler.fit(X_train[numeric_cols])\nencoder.fit(X_train[categorical_cols])\n\nX_train_scaled = scaler.transform(X_train[numeric_cols])\nX_test_scaled = scaler.transform(X_test[numeric_cols])\n\nX_train_encoded = encoder.transform(X_train[categorical_cols]).toarray()\nX_test_encoded = encoder.transform(X_test[categorical_cols]).toarray()\n\nX_train_final = np.concatenate([X_train_scaled, X_train_encoded], axis=1)\nX_test_final = np.concatenate([X_test_scaled, X_test_encoded], axis=1)\n\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train_final, y_train)\npredictions = knn.predict(X_test_final)\n\ncm = confusion_matrix(y_test, predictions)\n\nplt.figure(figsize=(6,4))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=l_encoder.classes_, yticklabels=l_encoder.classes_)\nplt.xlabel(\"Predito\")\nplt.ylabel(\"Real\")\nplt.title(\"Matriz de Confus\u00e3o - KNN Modelo 2\")\n\nplt.savefig(\"docs/images/cm_knn_modelo2.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre>"},{"location":"knn/main/#acuracia-dos-modelos","title":"Acur\u00e1cia dos modelos","text":"<p>Os modelos tiveram uma acur\u00e1cia muito pr\u00f3xima, ambas decentes, de 85,41% para o modelo 1 e 85,21% para o modelo 2.</p>"},{"location":"knn/main/#metricas-de-qualidade","title":"M\u00e9tricas de qualidade","text":"<p>Modelo 1:</p> <ul> <li> <p>Precis\u00e3o (Canceled): 1802 / (1802 + 600) = 75.03%</p> </li> <li> <p>Recall (Canceled): 1802 / (1802 + 459) = 79.70%</p> </li> <li> <p>F1-Score (Canceled): 77.30%</p> </li> </ul> <p>Modelo 2:</p> <ul> <li> <p>Precis\u00e3o (Canceled): 1788 / (1788 + 614) = 74.44%</p> </li> <li> <p>Recall (Canceled): 1788 / (1788 + 459) = 79.57%</p> </li> <li> <p>F1-Score (Canceled): 76.92%</p> </li> </ul>"},{"location":"knn/main/#analise-das-visualizacoes","title":"An\u00e1lise das visualiza\u00e7\u00f5es","text":"<p>Modelo 1:</p> <ul> <li> <p>Padr\u00e3o visual: Separa\u00e7\u00e3o mais \"limpa\" entre classes</p> </li> <li> <p>Componentes principais: Distribui\u00e7\u00e3o mais organizada</p> </li> </ul> <p>Modelo 2:</p> <ul> <li> <p>Padr\u00e3o visual: Separa\u00e7\u00e3o mais realista entre classes</p> </li> <li> <p>Componentes principais: Sobreposi\u00e7\u00e3o natural entre clusters</p> </li> </ul>"},{"location":"knn/main/#avaliacao-detalhada-entre-os-modelos","title":"Avalia\u00e7\u00e3o detalhada entre os modelos","text":""},{"location":"knn/main/#modelo-1","title":"Modelo 1","text":"<p>Pontos Fortes:</p> <ul> <li> <p>Acur\u00e1cia ligeiramente superior (86.04% vs 85.80%)</p> </li> <li> <p>Melhor precision para classe \"Canceled\" (75.03% vs 74.44%)</p> </li> <li> <p>Separa\u00e7\u00e3o visual mais clara no espa\u00e7o PCA</p> </li> </ul> <p>Pontos Fracos:</p> <ul> <li> <p>Performance artificialmente inflada</p> </li> <li> <p>Baixa confiabilidade para dados novos</p> </li> <li> <p>N\u00e3o representa cen\u00e1rios do mundo real</p> </li> </ul>"},{"location":"knn/main/#modelo-2","title":"Modelo 2","text":"<p>Pontos Fortes:</p> <ul> <li> <p>Performance realista e confi\u00e1vel</p> </li> <li> <p>Melhor generaliza\u00e7\u00e3o para dados n\u00e3o vistos</p> </li> <li> <p>Aplic\u00e1vel em ambiente de produ\u00e7\u00e3o</p> </li> </ul> <p>Pontos Fracos:</p> <ul> <li> <p>Performance ligeiramente inferior em n\u00fameros absolutos</p> </li> <li> <p>Separa\u00e7\u00e3o menos clara no espa\u00e7o PCA</p> </li> </ul>"},{"location":"knn/main/#etapa-5-relatorio-final","title":"Etapa 5 - Relat\u00f3rio Final","text":""},{"location":"knn/main/#recomendacoes-e-conclusoes","title":"Recomenda\u00e7\u00f5es e Conclus\u00f5es","text":"<p>\u00c9 recomendado o Modelo 2 (sem data leakage) porque:</p> <ul> <li> <p>Fornece estimativas realistas de performance</p> </li> <li> <p>\u00c9 mais robusto para dados novos</p> </li> <li> <p>Evita surpresas desagrad\u00e1veis em produ\u00e7\u00e3o</p> </li> <li> <p>Mant\u00e9m performance muito similar (diferen\u00e7a de apenas 0.2%)</p> </li> </ul>"},{"location":"knn/main/#pontos-importantes-observados","title":"Pontos Importantes Observados","text":"<ul> <li> <p>Data leakage cria uma falsa sensa\u00e7\u00e3o de seguran\u00e7a</p> </li> <li> <p>Diferen\u00e7as pequenas em m\u00e9tricas podem indicar problemas grandes</p> </li> <li> <p>A valida\u00e7\u00e3o rigorosa \u00e9 essencial para modelos confi\u00e1veis</p> </li> <li> <p>Performance visual nem sempre se traduz em performance real</p> </li> </ul>"},{"location":"knn/main/#possiveis-proximos-passos-e-melhorias","title":"Poss\u00edveis pr\u00f3ximos passos e melhorias","text":"<ul> <li> <p>Validar ambos modelos em um conjunto de dados totalmente novo</p> </li> <li> <p>Implementar o Modelo 2 em ambiente controlado</p> </li> <li> <p>Monitorar performance cont\u00ednua em produ\u00e7\u00e3o</p> </li> <li> <p>Considerar t\u00e9cnicas de regulariza\u00e7\u00e3o para melhorar generaliza\u00e7\u00e3o</p> </li> </ul>"},{"location":"knn/main/#conclusao-final","title":"Conclus\u00e3o Final","text":"<p>Embora o Modelo 1 apresente m\u00e9tricas ligeiramente superiores, o Modelo 2 \u00e9 significativamente mais confi\u00e1vel e adequado para implanta\u00e7\u00e3o em ambiente real devido \u00e0 aus\u00eancia de data leakage.</p>"}]}