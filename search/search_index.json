{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documenta\u00e7\u00e3o dos Projetos de Machine Learning","text":""},{"location":"#autor","title":"Autor","text":"<p>Luiz Felipe Pimenta Berrettini</p> <p>Estudante do 4\u00b0 semestre de Ci\u00eancias de Dados e Neg\u00f3cios (CDN) na ESPM (Escola Superior de Propaganda e Marketing).  Projetos de 2025.2.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Decision Tree - Data 29/08/2025</li> <li> KNN - Data 16/09/2025</li> </ul>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"decision-tree/main/","title":"Modelo de Machine Learning - \u00c1rvore de Decis\u00f5es","text":"<p>Para esse projeto, foi utilizado um dataset obtido no Kaggle. Os dados usados podem ser baixados aqui.</p>"},{"location":"decision-tree/main/#objetivo","title":"Objetivo","text":"<p>O dataset apresenta diversos dados relacionados \u00e0 cada um dos personagens da s\u00e9rie de livros A Song of Ice and Fire, escrita por George R. R. Martin, inspira\u00e7\u00e3o para a famosa s\u00e9rie Game of Thrones. O objetivo dessa an\u00e1lise \u00e9 o modelo fazer a predi\u00e7\u00e3o da import\u00e2ncia do personagem para a s\u00e9rie no sentido de trama. Uma vari\u00e1vel categ\u00f3rica ser\u00e1 criada a partir das vari\u00e1veis presentes no dataset, classificando a relev\u00e2ncia do personagem. Essa vari\u00e1vel ser\u00e1 avaliada pelo modelo de Machine Learning.</p>"},{"location":"decision-tree/main/#workflow","title":"Workflow","text":"<p>Os pontos \"etapas\" s\u00e3o o passo-a-passo da realiza\u00e7\u00e3o do projeto.</p>"},{"location":"decision-tree/main/#etapa-1-exploracao-de-dados","title":"Etapa 1 - Explora\u00e7\u00e3o de Dados","text":"<p>O dataset escolhido \u00e9 composto por 1946 linhas e 30 colunas, contendo um personagem distinto em cada linha e diversas informa\u00e7\u00f5es sobre cada um.</p>"},{"location":"decision-tree/main/#colunas-do-dataset","title":"Colunas do dataset","text":"Coluna Tipo Descri\u00e7\u00e3o S.No Inteiro Identificador \u00fanico do personagem plod Float Valor n\u00e3o especificado name String Nome do personagem title String Alcunha atribu\u00edda ao personagem dentro do mundo gender Bin\u00e1rio Sexo do personagem: 0 = feminino, 1 = masculino culture String Grupo social ao qual o personagem pertence dateOfBirth Inteiro Data de nascimento. Valores positivos = depois do ano 0, negativos = antes do ano 0 DateoFdeath Inteiro Data de morte. Valores positivos = depois do ano 0, negativos = antes do ano 0 mother String Nome da m\u00e3e do personagem father String Nome do pai do personagem heir String Nome do herdeiro do personagem house String Nome da casa \u00e0 qual o personagem pertence spouse String Nome do c\u00f4njuge do personagem book1 Bin\u00e1rio Indica se o personagem apareceu no primeiro livro book2 Bin\u00e1rio Indica se o personagem apareceu no segundo livro book3 Bin\u00e1rio Indica se o personagem apareceu no terceiro livro book4 Bin\u00e1rio Indica se o personagem apareceu no quarto livro book5 Bin\u00e1rio Indica se o personagem apareceu no quinto livro isAliveMother Bin\u00e1rio Indica se a m\u00e3e do personagem est\u00e1 viva isAliveFather Bin\u00e1rio Indica se o pai do personagem est\u00e1 vivo isAliveHeir Bin\u00e1rio Indica se o herdeiro do personagem est\u00e1 vivo isAliveSpouse Bin\u00e1rio Indica se o c\u00f4njuge do personagem est\u00e1 vivo isMarried Bin\u00e1rio Indica se o personagem \u00e9 casado isNoble Bin\u00e1rio Indica se o personagem \u00e9 nobre age Inteiro Idade do personagem (refer\u00eancia: ano 305 D.C.) numDeadRelations Inteiro N\u00famero de personagens mortos com os quais o personagem se relaciona boolDeadRelations Bin\u00e1rio Indica se h\u00e1 personagens mortos relacionados ao personagem isPopular Bin\u00e1rio Indica se o personagem \u00e9 considerado popular popularity Float \u00cdndice entre 0 e 1 que indica o qu\u00e3o popular \u00e9 o personagem isAlive Bin\u00e1rio Indica se o personagem est\u00e1 vivo"},{"location":"decision-tree/main/#estudo-da-coluna-plod","title":"Estudo da coluna <code>plod</code>","text":"<p>No dataset, temos uma coluna que possui um \u00edndice que aponta algo n\u00e3o identificado: o plod. Para investigar seu significado, s\u00e3o necess\u00e1rias algumas an\u00e1lises:</p> <ul> <li>Inspe\u00e7\u00e3o dos valores: Primeiro, foram realizadas algumas linhas de c\u00f3digo para verificar os valores da coluna;</li> </ul> Sa\u00eddaC\u00f3digo <p>Tipo de dado: float64</p> <p>Valor m\u00ednimo: 0.0</p> <p>Valor m\u00e1ximo: 1.0</p> <p>Valor m\u00e9dio: 0.366</p> <p>Exemplo de valor: 0.946</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs\\decision-tree\\dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\nprint(f\"Tipo de dado: {df[\"plod\"].dtype}\\n\")\nprint(f\"Valor m\u00ednimo: {df[\"plod\"].min()}\\n\")\nprint(f\"Valor m\u00e1ximo: {df[\"plod\"].max()}\\n\")\nprint(f\"Valor m\u00e9dio: {format(df[\"plod\"].mean(), \".3f\")}\\n\")\nprint(f\"Exemplo de valor: {df.loc[0, \"plod\"]}\")\n</code></pre> <p>A an\u00e1lise da sa\u00edda obtida nos permite observar que os valores est\u00e3o sempre no intervalo [0,1], sugerindo que representam uma probabilidade ou \u00edndice normalizado.</p> <ul> <li>Correla\u00e7\u00f5es entre <code>plod</code> e as outras colunas: Levando isso em considera\u00e7\u00e3o, \u00e9 necess\u00e1rio realizar um c\u00e1lculo de correla\u00e7\u00f5es para descobrir a principal vari\u00e1vel no c\u00e1lculo do plod:</li> </ul> Sa\u00eddaC\u00f3digo <p>popularity: 0.35458415491153905</p> <p>isAliveFather: -0.3525990385007833</p> <p>book4: -0.4041512952984149</p> <p>isAlive: -0.41731839569897605</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs\\decision-tree\\dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\ndf_numerico = df.select_dtypes(include=[\"number\"])\n\ncorrel = df_numerico.corr()[\"plod\"].sort_values(ascending=False)\n\nfor col, corr in correl.items():\n    if (corr &gt; 0.3 or corr &lt; -0.3) and corr != 1:\n        print(f\"{col}: {corr}\\n\")\n</code></pre> <p>\u00c9 poss\u00edvel observar que a correla\u00e7\u00e3o mais forte entre plod e qualquer outra coluna no dataset \u00e9 com a coluna isAlive. Esse dado nos permite criar uma hip\u00f3tese de que plod \u00e9 a estimativa da probabilidade de morte do personagem.</p> <ul> <li>Compara\u00e7\u00e3o com a coluna <code>isAlive</code>: Em seguida, para verificar a hip\u00f3tese estabelecida, ser\u00e1 feito um gr\u00e1fico de boxplot para analisar a rela\u00e7\u00e3o de plod e isAlive;</li> </ul> Gr\u00e1ficoC\u00f3digo 2025-08-29T08:50:45.454937 image/svg+xml Matplotlib v3.10.5, https://matplotlib.org/ <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs\\decision-tree\\dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\nplod_alive = df[df[\"isAlive\"] == 1][\"plod\"]\nplod_dead = df[df[\"isAlive\"] == 0][\"plod\"]\n\nplt.rcParams[\"figure.figsize\"] = (10, 5)\nfig, ax = plt.subplots(facecolor=\"white\")\nax.set_facecolor(\"white\")\n\nax.boxplot([plod_alive, plod_dead], labels=[\"Vivo\", \"Morto\"],\n           patch_artist=True,\n           boxprops=dict(facecolor=\"lightblue\", color=\"black\"),\n           medianprops=dict(color=\"red\"))\n\nax.set_title(\"Distribui\u00e7\u00e3o de plod por estado de vida\", color=\"black\")\nax.set_ylabel(\"plod (probabilidade de morte)\", color=\"black\")\nax.set_xlabel(\"Estado de vida (isAlive)\", color=\"black\")\nax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7, color=\"gray\")\n\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.spines[\"left\"].set_color(\"black\")\nax.spines[\"bottom\"].set_color(\"black\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> <p>No gr\u00e1fico, observa-se que personagens vivos (isAlive = 1) tendem a possuir baixos valores de plod, enquanto personagens mortos (isAlive = 0) geralmente t\u00eam valores altos. Al\u00e9m disso, \u00e9 poss\u00edvel observar diversos outliers dentre os personagens vivos, que s\u00e3o provavelmente personagens que aparecem pouco e/ou possuem informa\u00e7\u00f5es incompletas. Essa ideia \u00e9 fortalecida pelo fato de que a vari\u00e1vel popularity (popularidade) tamb\u00e9m possui correla\u00e7\u00e3o moderada com plod.</p> <p>Portanto, os padr\u00f5es do gr\u00e1fico indicam, novamente, que plod funciona como uma estimativa da probabilidade de morte do personagem, refor\u00e7ando a hip\u00f3tese inicial. Essa coluna provavelmente foi calculada com algum modelo preditivo anterior.</p> <p>\u00c9 necess\u00e1rio ressaltar que isso \u00e9 uma observa\u00e7\u00e3o explorat\u00f3ria, baseada nos dados dispon\u00edveis, e ser\u00e1 considerada no pr\u00e9-processamento e na escolha das features do modelo.</p>"},{"location":"decision-tree/main/#exploracao-aprofundada-da-coluna-popularity","title":"Explora\u00e7\u00e3o aprofundada da coluna <code>popularity</code>","text":"<ul> <li>Estat\u00edsticas descritivas: Primeiramente, vamos calcular alguns valores essenciais dessa coluna;</li> </ul> Sa\u00eddaC\u00f3digo popularity count 1946 mean 0.0895843 std 0.160568 min 0 25% 0.0133779 50% 0.0334448 75% 0.0869565 max 1 <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs\\decision-tree\\dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\nprint(df[\"popularity\"].describe().to_markdown())\n</code></pre> <p>Na sa\u00edda, observa-se que popularity \u00e9 um \u00edndice que indica a popularidade do personagem, variando entre 0 e 1, com o valor 0 para irrelevante e 1 para popular.</p> <ul> <li>Gr\u00e1fico de dispers\u00e3o de <code>popularity</code>: O gr\u00e1fico relaciona o \u00edndice popularity com a soma das 5 vari\u00e1veis book, que indicam a presen\u00e7a de um personagem em cada livro em bin\u00e1rio. Os livros considerados nessas vari\u00e1veis s\u00e3o apenas a narrativa principal da hist\u00f3ria, sem spin-offs e personagens que s\u00e3o apenas citados e referenciados.</li> </ul> Gr\u00e1ficoC\u00f3digo 2025-08-29T08:50:45.708002 image/svg+xml Matplotlib v3.10.5, https://matplotlib.org/ <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/decision-tree/dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\ndf[\"book_freq\"] = df[[\"book1\", \"book2\", \"book3\", \"book4\", \"book5\"]].sum(axis=1)\n\nplt.rcParams[\"figure.figsize\"] = (10, 5)\nfig, ax = plt.subplots(facecolor=\"white\")\nax.set_facecolor(\"white\")\n\nax.scatter(df[\"book_freq\"], df[\"popularity\"], alpha=0.7, color=\"red\", edgecolor=\"black\")\n\nax.set_title(\"Popularidade X Frequ\u00eancia nos livros\", color=\"black\")\nax.set_xlabel(\"Frequ\u00eancia em livros (soma)\", color=\"black\")\nax.set_ylabel(\"Popularidade\", color=\"black\")\nax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7, color=\"gray\")\n\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.spines[\"left\"].set_color(\"black\")\nax.spines[\"bottom\"].set_color(\"black\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\n</code></pre> <p>A an\u00e1lise do gr\u00e1fico indica que, de 1 at\u00e9 5 apari\u00e7\u00f5es, o n\u00famero de personagens populares aumenta de forma diretamente proporcional, com alguns out-liers.</p> <p>Contudo, podemos observar que diversos personagens que n\u00e3o apareceram na s\u00e9rie principal de livros, possuindo soma de apari\u00e7\u00f5es igual a 0, s\u00e3o extremamente populares. Isso acontece pois h\u00e1 personagens de spin-offs muito amados pela comunidade, al\u00e9m de outros personagens que s\u00e3o apenas citados ao longo da hist\u00f3ria, sem aparecer diretamente, e tamb\u00e9m adquirem alta popularidade.</p>"},{"location":"decision-tree/main/#etapa-2-pre-processamento","title":"Etapa 2 - Pr\u00e9-processamento","text":"<p>O objetivo do projeto \u00e9 realizar uma predi\u00e7\u00e3o da relev\u00e2ncia dos personagens na trama principal, a vari\u00e1vel categ\u00f3rica relevance que possuir\u00e1 as seguintes categorias: Low, Medium, High e Very High. </p>"},{"location":"decision-tree/main/#1-passo-criacao-de-book_freq","title":"1\u00b0 Passo: Cria\u00e7\u00e3o de <code>book_freq</code>","text":"<p>Primeiramente, \u00e9 importante criar uma vari\u00e1vel representante para a frequ\u00eancia em livros para cada personagem. Ao inv\u00e9s de utilizar 5 vari\u00e1veis book diferentes, criaremos a vari\u00e1vel boof_freq. Para isso, ser\u00e1 feita a soma dos 5 valores das vari\u00e1veis book, o que resultar\u00e1 em um intervalo de [0,5]. Contudo, para que esse valores sejam normalizados, e possuam um n\u00famero entre 0 e 1, \u00e9 feita a divis\u00e3o desse resultado por 5.</p> <pre><code>df[\"book_freq\"] = df[[\"book1\", \"book2\", \"book3\", \"book4\",\"book5\"]].sum(axis=1) / 5\n</code></pre>"},{"location":"decision-tree/main/#2-passo-selecao-de-colunas","title":"2\u00b0 Passo: Sele\u00e7\u00e3o de colunas","text":"<p>Em seguida, \u00e9 necess\u00e1rio definir quais s\u00e3o as vari\u00e1veis ser\u00e3o utilizadas para prever a relev\u00e2ncia. Elas s\u00e3o as seguintes:</p> <ul> <li> <p>plod: Se esse valor for alto, h\u00e1 maior chance do personagem ser irrelevante </p> </li> <li> <p>title: Se o personagem tiver um t\u00edtulo, qualquer que seja, j\u00e1 possui alguma relev\u00e2ncia </p> </li> <li> <p>culture: Se o personagem tiver alguma cultura, qualquer que seja, j\u00e1 possui alguma relev\u00e2ncia </p> </li> <li> <p>mother: Se o personagem tiver paretentesco revelado, provavelmente tem alguma import\u00e2ncia </p> </li> <li> <p>father: Se o personagem tiver paretentesco revelado, provavelmente tem alguma import\u00e2ncia </p> </li> <li> <p>heir: Se o personagem tiver paretentesco revelado, provavelmente tem alguma import\u00e2ncia </p> </li> <li> <p>house: Se o personagem tiver uma casa, deve ser mais relevante </p> </li> <li> <p>book_freq: Se o personagem aparece frequentemente, deve ser relevante </p> </li> <li> <p>isNoble: Se o personagem for um nobre, tem mais chances de ser importante </p> </li> <li> <p>popularity: Se o personagem for popular, tamb\u00e9m aumenta sua chance de relev\u00e2ncia </p> </li> </ul> <p>A sele\u00e7\u00e3o das colunas foi feita, em c\u00f3digo, da seguinte forma: <pre><code>cols = [\"plod\", \"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\",\n\"book_freq\", \"isNoble\", \"popularity\"]\n\ndf = df[cols]\n</code></pre></p>"},{"location":"decision-tree/main/#3-passo-tratamento-de-valores-faltantes","title":"3\u00b0 Passo: Tratamento de valores faltantes","text":"<p>Precisamos garantir que n\u00e3o existam valores faltantes no dataframe. Por isso, ser\u00e1 feita uma altera\u00e7\u00e3o em todas as linhas restantes que possuem valor NA. Contudo, temos que tratar diferentemente cada tipo de vari\u00e1vel para o preenchimento dos vazios. As regras utilizadas ser\u00e3o as seguintes:</p> <ul> <li> <p>Faltantes n\u00famericos ser\u00e3o preenchidos com a mediana da coluna - plod, popularity</p> </li> <li> <p>Faltantes categ\u00f3ricos nominais ser\u00e3o preenchidos com \"Unknown\" (Desconhecido) - title, culture, mother, father, heir, house</p> </li> <li> <p>Faltantes bin\u00e1rios ser\u00e3o preenchidos com a moda da coluna (valor mais frequente) - isNoble</p> </li> </ul> <pre><code>cols = [\"plod\", \"popularity\"]\nfor col in cols:\n    df.fillna({col: df[col].median()}, inplace=True)\n\ncols = [\"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\"]\nfor col in cols:\n    df.fillna({col: \"Unknown\"}, inplace=True)\n\ndf.fillna({\"isNoble\": df[\"isNoble\"].mode()[0]}, inplace=True)\n</code></pre>"},{"location":"decision-tree/main/#4-passo-binarizacao-dos-categoricos-nominais","title":"4\u00b0 Passo: Binariza\u00e7\u00e3o dos categ\u00f3ricos nominais","text":"<p>As vari\u00e1veis categ\u00f3ricas no dataframe tem, simplesmente, muitas categorias para a realiza\u00e7\u00e3o de Label ou One-hot Encoding. Al\u00e9m disso, o \u00fanico dado importante provindo dessas no modelo sendo criado \u00e9 se existem ou n\u00e3o essas informa\u00e7\u00f5es sobre o personagem. Portanto, as colunas title, culture, mother, father, heir e house ser\u00e3o binarizadas. Ou seja, se possu\u00edrem um valor, assumir\u00e3o o valor 1. Caso contr\u00e1rio, 0. </p> <p>Al\u00e9m disso, os nomes das colunas ser\u00e3o alterados, adicionando um \"has_\" antes do nome original da vari\u00e1vel.</p> <pre><code>cols = [\"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\"]\n\nfor col in cols:\n    df[f\"has_{col}\"] = (df[col] != \"Unknown\").astype(int)\n    df.drop(columns=[col], inplace=True)\n</code></pre>"},{"location":"decision-tree/main/#5-passo-inversao-e-renomeacao-de-plod","title":"5\u00b0 Passo: Invers\u00e3o e renomea\u00e7\u00e3o de <code>plod</code>","text":"<p>A vari\u00e1vel plod, que indica a probabilidade de morte, possui uma rela\u00e7\u00e3o inversamente proporcional \u00e0 relev\u00e2ncia do personagem. Por isso, \u00e9 necess\u00e1ria a invers\u00e3o dessa vari\u00e1vel. Al\u00e9m disso, renomear a vari\u00e1vel para survival_prob deixar\u00e1 mais claro o seu prop\u00f3sito.</p> <pre><code>df[\"survival_prob\"] = 1 - df[\"plod\"]\ndf.drop(columns=\"plod\", inplace=True)\n</code></pre>"},{"location":"decision-tree/main/#6-passo-criacao-da-variavel-target-relevance_category-a-partir-do-score-relevance_score","title":"6\u00b0 Passo: Cria\u00e7\u00e3o da vari\u00e1vel target <code>relevance_category</code> a partir do score <code>relevance_score</code>","text":"<p>Agora, precisamos criar a vari\u00e1vel categ\u00f3rica que ser\u00e1 avaliada pelo modelo. Utilizaremos a seguinte distribui\u00e7\u00e3o de pesos:</p> <ul> <li> <p>popularity: Popularidade - 25%</p> </li> <li> <p>book_freq: Frequ\u00eancia de apari\u00e7\u00f5es - 25%</p> </li> <li> <p>survival_prob: Probabilidade de sobreviv\u00eancia - 15%</p> </li> <li> <p>isNoble: \u00c9 nobre - 10%</p> </li> <li> <p>has_title: Tem um t\u00edtulo - 10%</p> </li> <li> <p>has_house: Possui uma casa - 5%</p> </li> <li> <p>has_culture: Tem uma cultura - 5%</p> </li> <li> <p>has_mother + has_father + has_heir: Possui parentesco - 5%</p> </li> </ul> <p>Com o relevance_score definido, criaremos a nova coluna, relevance_category, a partir dos seguintes valores de score:</p> <ul> <li> <p>x &lt; 0.25: Low (Baixa relev\u00e2ncia)</p> </li> <li> <p>0.25 &lt;= x &lt; 0.5: Medium (Relev\u00e2ncia m\u00e9dia)</p> </li> <li> <p>0.5 &lt;= x &lt; 0.75: High (Alta relev\u00e2ncia)</p> </li> <li> <p>0.75 &lt;= x &lt;= 1: Very High (Relev\u00e2ncia muito alta)</p> </li> </ul>"},{"location":"decision-tree/main/#resultado-final-do-pre-processamento","title":"Resultado final do pr\u00e9-processamento","text":"Sa\u00eddaC\u00f3digo <p>Colunas ap\u00f3s tratamento: ['book_freq', 'isNoble', 'popularity', 'has_title', 'has_culture', 'has_mother', 'has_father', 'has_heir', 'has_house', 'survival_prob', 'relevance_score', 'relevance_category']</p> <p>Valores ausentes ap\u00f3s pr\u00e9-processamento: 0</p> <p>Formato do dataset final: (1946, 12)</p> <p>Features: 10</p> <p>Target: relevance_category</p> <p>Distribui\u00e7\u00e3o da vari\u00e1vel target:</p> relevance_category count Medium 1078 Low 458 High 379 Very High 31 <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs\\decision-tree\\dados.csv\", sep=\",\", encoding=\"UTF-8\")\n\n# 1\u00b0 Passo: Criando a coluna \"book_freq\", j\u00e1 normalizando-a\n\ndf[\"book_freq\"] = df[[\"book1\", \"book2\", \"book3\", \"book4\", \"book5\"]].sum(axis=1) / 5\n\n# 2\u00b0 Passo: Dropando colunas que n\u00e3o ser\u00e3o utilizadas\n\ncols = [\n    \"plod\", \"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\", \"book_freq\", \"isNoble\", \"popularity\"\n]\n\ndf = df[cols]\n\n# 3\u00b0 Passo: Tratamento de valores faltantes\n\ncols = [\"plod\", \"popularity\"]\nfor col in cols:\n    df.fillna({col: df[col].median()}, inplace=True)\n\ncols = [\"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\"]\nfor col in cols:\n    df.fillna({col: \"Unknown\"}, inplace=True)\n\ndf.fillna({\"isNoble\": df[\"isNoble\"].mode()[0]}, inplace=True)\n\n# 4\u00b0 Passo: Binariza\u00e7\u00e3o das vari\u00e1veis categ\u00f3ricas nominais\n\ncols = [\"title\", \"culture\", \"mother\", \"father\", \"heir\", \"house\"]\n\nfor col in cols:\n    df[f\"has_{col}\"] = (df[col] != \"Unknown\").astype(int)\n    df.drop(columns=[col], inplace=True)\n\n# 5\u00b0 Passo: Invers\u00e3o da vari\u00e1vel \"plod\" e renomea\u00e7\u00e3o para \"survival_prob\"\n\ndf[\"survival_prob\"] = 1 - df[\"plod\"]\ndf.drop(columns=\"plod\", inplace=True)\n\n# 6\u00b0 Passo: Criar vari\u00e1vel target \"relevance_category\" a partir do score \"relevance_score\"\n\ndef calculate_relevance_score(row):\n\n    score = (\n        row[\"popularity\"] * 0.25 +\n        row[\"book_freq\"] * 0.25 +\n        row[\"survival_prob\"] * 0.15 +\n        row[\"isNoble\"] * 0.10 +\n        row[\"has_title\"] * 0.10 +\n        row[\"has_house\"] * 0.05 +\n        row[\"has_culture\"] * 0.05 +\n        (row[\"has_mother\"] + row[\"has_father\"] + row[\"has_heir\"]) * 0.05 / 3\n    )\n\n    return min(max(score, 0), 1)\n\ndef categorize_relevance(score):\n    if score &lt; 0.25:\n        return \"Low\"\n    elif score &lt; 0.5:\n        return \"Medium\"\n    elif score &lt; 0.75:\n        return \"High\"\n    else:\n        return \"Very High\"\n\ndf[\"relevance_score\"] = df.apply(calculate_relevance_score, axis=1)\ndf[\"relevance_category\"] = df[\"relevance_score\"].apply(categorize_relevance)\n\nfeatures = [\n    \"book_freq\", \"popularity\", \"survival_prob\", \"isNoble\",    \n    \"has_title\", \"has_culture\", \"has_mother\", \"has_father\", \n    \"has_heir\", \"has_house\",\n]\n\ntarget = \"relevance_category\"\n\n# df.to_csv(\"dados_processado.csv\", index=False)\n\nprint(f\"Colunas ap\u00f3s tratamento: {df.columns.tolist()}\\n\")\nprint(f\"Valores ausentes ap\u00f3s pr\u00e9-processamento: {df.isnull().sum().sum()}\\n\") \nprint(f\"Formato do dataset final: {df.shape}\\n\")\nprint(f\"Features: {len(features)}\\n\")\nprint(f\"Target: {target}\\n\")\nprint(f\"Distribui\u00e7\u00e3o da vari\u00e1vel target:\\n\")\nprint(df[target].value_counts().to_markdown())\n</code></pre>"},{"location":"decision-tree/main/#etapa-3-divisao-de-dados","title":"Etapa 3 - Divis\u00e3o de dados","text":"<p>Na etapa de divis\u00e3o de dados, separaremos o conjunto de dados processado em dois grupos distintos:</p> <ul> <li> <p>Conjunto de Treino: \u00c9 utilizado para ensinar o modelo a reconhecer padr\u00f5es</p> </li> <li> <p>Conjunto de Teste: \u00c9 utilizado para avaliar o desempenho do modelo com dados ainda n\u00e3o vistos</p> </li> </ul> <p>Para realizar a divis\u00e3o, utilizaremos a fun\u00e7\u00e3o <code>train_test_split()</code> do <code>scikit-learn</code>. Os par\u00e2metros utilizados ser\u00e3o:</p> <ul> <li> <p>test_size=0.2: Define que 20% dos dados ser\u00e3o utilizados para teste, enquanto o restante ser\u00e1 usado para treino.</p> </li> <li> <p>random_state=42: Par\u00e2metro que controla o gerador de n\u00famero aleat\u00f3rios utilizado para sortear os dados antes de separ\u00e1-los. Garante reprodutibilidade.</p> </li> <li> <p>stratify=y: Esse atributo definido como y \u00e9 essencial devido \u00e0 natureza da coluna relevance_category. Com essa defini\u00e7\u00e3o, ser\u00e1 mantida a mesma propor\u00e7\u00e3o das categorias em ambos os conjuntos, reduzindo o vi\u00e9s.</p> </li> </ul> Sa\u00eddaC\u00f3digo <p>Treino: 1556 amostras</p> <p>Teste: 390 amostras</p> <p>Propor\u00e7\u00e3o: 80.0% treino, 20.0% teste</p> <p>Distribui\u00e7\u00e3o das classes - </p> <p>Treino:</p> relevance_category count Medium 862 Low 366 High 303 Very High 25 <p>Teste:</p> relevance_category count Medium 216 Low 92 High 76 Very High 6 <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"dados_processado.csv\")\n\nfeatures = [\n    \"book_freq\", \"popularity\", \"survival_prob\", \"isNoble\",\n    \"has_title\", \"has_culture\", \"has_mother\", \"has_father\", \n    \"has_heir\", \"has_house\"\n]\n\ntarget = \"relevance_category\"\n\nx = df[features]\ny = df[target]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n\nprint(f\"Treino: {x_train.shape[0]} amostras\\n\")\nprint(f\"Teste: {x_test.shape[0]} amostras\\n\")\nprint(f\"Propor\u00e7\u00e3o: {x_train.shape[0]/x.shape[0]*100:.1f}% treino, {x_test.shape[0]/x.shape[0]*100:.1f}% teste\\n\")\n\nprint(\"Distribui\u00e7\u00e3o das classes - \\n\")\nprint(\"Treino:\\n\")\nprint(y_train.value_counts().to_markdown(), \"\\n\")\nprint(\"Teste:\\n\")\nprint(y_test.value_counts().to_markdown(), \"\\n\")\n</code></pre> <p>Os dados, agora, est\u00e3o devidamente divididos. Esta divis\u00e3o adequada \u00e9 de extrema import\u00e2ncia, pois ajuda a evitar overfitting e garante que o modelo possa generalizar bem para novos personagens n\u00e3o vistos durante o treinamento.</p>"},{"location":"decision-tree/main/#etapa-4-treinamento-do-modelo","title":"Etapa 4 - Treinamento do Modelo","text":"<p>Agora, ser\u00e1 realizado o treinamento do modelo. O objetivo dessa etapa \u00e9 ensinar o algoritmo a reconhecer padr\u00f5es nos dados que s\u00e3o fornecidos, e determinar a import\u00e2ncia narrativa de cada personagem na s\u00e9rie principal de livros de A Song of Ice and Fire.</p> Gr\u00e1ficoC\u00f3digo <p>Precis\u00e3o do Modelo: 0.9513 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 book_freq 0.439754 2 survival_prob 0.200915 3 isNoble 0.146227 1 popularity 0.102306 5 has_culture 0.054061 9 has_house 0.034825 4 has_title 0.021911 6 has_mother 0.000000 7 has_father 0.000000 8 has_heir 0.000000 2025-08-29T08:50:56.371129 image/svg+xml Matplotlib v3.10.5, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom io import StringIO\n\ndf = pd.read_csv(\"dados_processado.csv\")\n\nfeatures = [\n    \"book_freq\", \"popularity\", \"survival_prob\", \"isNoble\",\n    \"has_title\", \"has_culture\", \"has_mother\", \"has_father\", \n    \"has_heir\", \"has_house\"\n]\n\ntarget = \"relevance_category\"\n\nx = df[features]\ny = df[target]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n\nclassifier = tree.DecisionTreeClassifier(random_state=42)\nclassifier.fit(x_train, y_train)\n\ny_pred = classifier.predict(x_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Precis\u00e3o do Modelo: {accuracy:.4f}\")\n\nfeature_importance = pd.DataFrame({\n    \"Feature\": classifier.feature_names_in_,\n    \"Import\u00e2ncia\": classifier.feature_importances_\n})\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.sort_values(by=\"Import\u00e2ncia\", ascending=False).to_html() + \"&lt;br&gt;\")\n\nplt.figure(figsize=(20, 10))\ntree.plot_tree(\n    classifier, \n    feature_names=features,\n    class_names=classifier.classes_,\n    filled=True,\n    rounded=True,\n    max_depth=3, \n    fontsize=10\n)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"decision-tree/main/#etapa-5-avaliacao-do-modelo","title":"Etapa 5 - Avalia\u00e7\u00e3o do modelo","text":""},{"location":"decision-tree/main/#acuracia-do-modelo","title":"Acur\u00e1cia do modelo","text":"<p>O modelo alcan\u00e7ou uma acur\u00e1cia impressionante de 95,13% no conjunto teste, demonstrando uma \u00f3tima capacidade de previs\u00e3o com personagens ainda n\u00e3o vistos com base nas features escolhidas.</p>"},{"location":"decision-tree/main/#importancia-das-features","title":"Import\u00e2ncia das features","text":"<p>A an\u00e1lise da import\u00e2ncia das features revela quais foram as vari\u00e1veis mais importantes para a previs\u00e3o e decis\u00f5es do modelo:</p> Feature Import\u00e2ncia Descri\u00e7\u00e3o <code>book_freq</code> 43,98% Frequ\u00eancia de apari\u00e7\u00e3o nos livros da s\u00e9rie principal <code>survival_prob</code> 20,09% Probabilidade de sobreviv\u00eancia <code>isNoble</code> 14,62% Status nobre <code>popularity</code> 10,23% \u00cdndice de popularidade <code>has_culture</code> 5,41% Possui cultura conhecida <code>has_house</code> 3,48% Pertence a uma casa <code>has_title</code> 2,19% Tem algum t\u00edtulo <code>has_mother</code> 0,00% H\u00e1 informa\u00e7\u00e3o sobre a m\u00e3e <code>has_father</code> 0,00% H\u00e1 informa\u00e7\u00e3o sobre o pai <code>has_heir</code> 0,00% Possui herdeiro"},{"location":"decision-tree/main/#insights-importantes-sobre-o-modelo","title":"Insights importantes sobre o modelo","text":"<ul> <li> <p>Frequ\u00eancia em livros \u00e9 determinante: A feature <code>book_freq</code> responde \u00e0 aproximadamente 44% da import\u00e2ncia, confirmando que personagens com mais apari\u00e7\u00f5es em diferentes livros da s\u00e9rie principal possuem maior import\u00e2ncia.</p> </li> <li> <p>Features desnecess\u00e1rias: O modelo tamb\u00e9m demonstrou que algumas features (has_mother, has_father, has_heir) n\u00e3o t\u00eam nenhuma import\u00e2ncia na predi\u00e7\u00e3o.</p> </li> </ul>"},{"location":"decision-tree/main/#etapa-6-relatorio-final","title":"Etapa 6 - Relat\u00f3rio Final","text":"<p>O projeto geral foi um sucesso, com a obten\u00e7\u00e3o de um modelo com uma acur\u00e1cia de 95,13%. O modelo, al\u00e9m de alta performance, possui features relevantes identificadas e bem estabelecidas: <code>book_freq</code>, <code>survival_prob</code> e <code>isNoble</code>.</p>"},{"location":"decision-tree/main/#limitacoes-do-modelo","title":"Limita\u00e7\u00f5es do modelo","text":"<p>Contudo, h\u00e1 limita\u00e7\u00f5es no modelo:</p> <ul> <li> <p>Features Redudantes: has_mother, has_father e has_heir possuem import\u00e2ncia nula para a predi\u00e7\u00e3o do sistema</p> </li> <li> <p>Poss\u00edvel vi\u00e9s: \u00c9 poss\u00edvel que, pela vari\u00e1vel relevance_score ter sido manualmente estabelecida, pode haver vi\u00e9s</p> </li> </ul>"},{"location":"decision-tree/main/#possiveis-melhorias","title":"Poss\u00edveis melhorias","text":"<ul> <li> <p>Valida\u00e7\u00e3o de <code>plod</code>: Durante a primeira etapa, na explora\u00e7\u00e3o da base de dados, poderia ter sido feita uma Regress\u00e3o Linear M\u00faltipla completa para validar completamente a hip\u00f3tese de que plod \u00e9 a probabilidade de morte do personagem.</p> </li> <li> <p>Remo\u00e7\u00e3o de features desnecess\u00e1rias: As features relacionadas \u00e0 parentesco podem ser removidas do modelo sem nenhum impacto na predi\u00e7\u00e3o.</p> </li> </ul>"},{"location":"decision-tree/main/#consideracoes-finais","title":"Considera\u00e7\u00f5es finais","text":"<p>A \u00e1rvore de decis\u00e3o se mostrou muito capaz de fazer a predi\u00e7\u00e3o de narrativas liter\u00e1rias complexas como A Song of Ice and Fire. Al\u00e9m do excelente resultado de acur\u00e1cia, foram providos insights importantes sobre a obra pelo modelo. </p> <p>Al\u00e9m disso, foi poss\u00edvel observar que tanto a Etapa 1 quanto a Etapa 2 foram muito mais longas do que as posteriores, demonstrando a import\u00e2ncia de entender e limpar o dataset antes do uso.</p>"}]}